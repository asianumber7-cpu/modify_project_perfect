import logging
import json
import re
import base64
from fastapi import FastAPI, HTTPException, APIRouter, UploadFile, File
from pydantic import BaseModel
from typing import List, Optional, Dict
from contextlib import asynccontextmanager

from src.core.model_engine import model_engine
from src.core.prompts import VISION_ANALYSIS_PROMPT

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info("ğŸš€ AI Service Starting...")
    try:
        model_engine.initialize()
    except Exception as e:
        logger.error(f"âš ï¸ Model init warning: {e}")
    yield
    logger.info("ğŸ’¤ AI Service Shutting down...")

app = FastAPI(title="Modify AI Service", version="1.0.0", lifespan=lifespan)
api_router = APIRouter(prefix="/api/v1")

# --- DTO ---
class EmbedRequest(BaseModel):
    text: str

class EmbedResponse(BaseModel):
    vector: List[float]

class ImageAnalysisResponse(BaseModel):
    name: str
    category: str
    gender: str
    description: str
    price: int
    vector: List[float]

class PathRequest(BaseModel):
    query: str

class InternalSearchRequest(BaseModel):
    query: str
    image_b64: Optional[str] = None

class SearchProcessResponse(BaseModel):
    vector: List[float]
    reason: str

# --- Helper Methods ---

def _fix_encoding(text: str) -> str:
    """
    [í•µì‹¬] ê¹¨ì§„ í•œê¸€(Mojibake) ë° ìœ ë‹ˆì½”ë“œ ì´ìŠ¤ì¼€ì´í”„ ì™„ë²½ ë³µêµ¬
    Case 1: "Ã­Â¬Ã«Â¦Â¬..." (UTF-8 bytes read as Latin-1) -> "í¬ë¦¬..."
    Case 2: "\ud558..." (Unicode Escape) -> "í•˜..."
    """
    if not text:
        return ""

    # 1. Mojibake ë³µêµ¬ ì‹œë„ (Latin-1 -> UTF-8)
    try:
        # ê¹¨ì§„ ë¬¸ìì—´ì„ ë‹¤ì‹œ ë°”ì´íŠ¸ë¡œ ëŒë¦¬ê³ (latin1), UTF-8ë¡œ ë‹¤ì‹œ ì½ìŒ
        fixed = text.encode('latin1').decode('utf-8')
        return fixed
    except Exception:
        pass

    # 2. ìœ ë‹ˆì½”ë“œ ì´ìŠ¤ì¼€ì´í”„ ë³µêµ¬ ì‹œë„
    try:
        return text.encode('utf-8').decode('unicode_escape')
    except Exception:
        pass
        
    return text

def _extract_from_text(text: str, key_patterns: List[str], default: str = "") -> str:
    """JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì •ê·œì‹ ì¶”ì¶œ + ì¸ì½”ë”© ìë™ ë³´ì •"""
    for pattern in key_patterns:
        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
        if match:
            clean_val = match.group(1).strip().strip('",').strip()
            return _fix_encoding(clean_val) # ì¶”ì¶œí•œ ê°’ë„ ì¸ì½”ë”© ë³´ì •
    return default

# --- Endpoints ---

@api_router.post("/embed-text", response_model=EmbedResponse)
async def embed_text(request: EmbedRequest):
    try:
        vector = model_engine.generate_embedding(request.text)
        return {"vector": vector}
    except:
        return {"vector": [0.0] * 768} 

@api_router.post("/analyze-image", response_model=ImageAnalysisResponse)
async def analyze_image(file: UploadFile = File(...)):
    filename = file.filename
    try:
        contents = await file.read()
        image_b64 = base64.b64encode(contents).decode("utf-8")
        
        prompt = VISION_ANALYSIS_PROMPT
        
        logger.info(f"ğŸ‘ï¸ Analyzing image: {filename}...")
        generated_text = model_engine.generate_with_image(prompt, image_b64)
        
        # [Critical] 1ì°¨ ì¸ì½”ë”© ë³´ì • (ì „ì²´ í…ìŠ¤íŠ¸ ë³µêµ¬)
        generated_text = _fix_encoding(generated_text)
        logger.info(f"ğŸ¤– Raw AI Response: {generated_text}")

        # [Safety Check]
        if "cannot assist" in generated_text or "I cannot" in generated_text:
            raise ValueError("AI Safety Filter Triggered")

        # [Parsing Logic]
        product_data = {}
        parsing_success = False

        # ì „ëµ 1: JSON íŒŒì‹±
        try:
            json_match = re.search(r"\{[\s\S]*\}", generated_text)
            if json_match:
                clean_json = json_match.group()
                clean_json = re.sub(r"```json|```", "", clean_json)
                product_data = json.loads(clean_json)
                parsing_success = True
            else:
                product_data = json.loads(generated_text)
                parsing_success = True
        except Exception as e:
            logger.warning(f"âš ï¸ JSON Parsing failed: {e}. Attempting Fallback Regex...")

        # ì „ëµ 2: Fallback Parser
        if not parsing_success:
            logger.info("ğŸ”§ Running Fallback Parser...")
            
            product_data["name"] = _extract_from_text(
                generated_text, 
                [r'"?name"?\s*:\s*"([^"]+)"', r'"?ì´ë¦„"?\s*:\s*"([^"]+)"', r'Name:\s*(.+)']
            )
            product_data["category"] = _extract_from_text(
                generated_text, 
                [r'"?category"?\s*:\s*"([^"]+)"', r'"?ì¹´í…Œê³ ë¦¬"?\s*:\s*"([^"]+)"', r'Category:\s*(.+)'
                ], "Uncategorized"
            )
            product_data["gender"] = _extract_from_text(
                generated_text,
                [r'"?gender"?\s*:\s*"([^"]+)"', r'"?ì„±ë³„"?\s*:\s*"([^"]+)"', r'Gender:\s*(.+)'],
                "Unisex"
            )
            product_data["description"] = _extract_from_text(
                generated_text,
                [r'"?description"?\s*:\s*"([^"]+)"', r'"?ì„¤ëª…"?\s*:\s*"([^"]+)"', r'Description:\s*(.+)'],
                "AI ìƒì„¸ ë¶„ì„ ë‚´ìš©ì…ë‹ˆë‹¤."
            )
            
            price_str = _extract_from_text(
                generated_text,
                [r'"?price"?\s*:\s*([\d,]+)', r'"?ê°€ê²©"?\s*:\s*([\d,]+)', r'Price:\s*([\d,]+)'],
                "0"
            )
            try:
                product_data["price"] = int(re.sub(r"[^0-9]", "", price_str))
            except:
                product_data["price"] = 0

        # [Normalization & 2ì°¨ ì¸ì½”ë”© ë³´ì •]
        # JSONìœ¼ë¡œ íŒŒì‹±ë˜ì—ˆë”ë¼ë„ ê°’ ë‚´ë¶€ê°€ ê¹¨ì ¸ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í•œë²ˆ ë” ì²´í¬
        final_name = _fix_encoding(product_data.get("name"))
        if not final_name or "ìƒí’ˆëª…" in final_name or "JSON" in final_name:
             final_name = f"AI ì¶”ì²œ ìƒí’ˆ ({filename.split('.')[0]})"
        
        final_desc = _fix_encoding(product_data.get("description"))
        if not final_desc or len(final_desc) < 5:
            final_desc = "AIê°€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì¶”ì²œí•˜ëŠ” ìƒí’ˆì…ë‹ˆë‹¤."

        final_cat = _fix_encoding(product_data.get("category", "Uncategorized"))
        
        raw_gender = str(product_data.get("gender", "Unisex"))
        if any(x in raw_gender.lower() for x in ['wo', 'female', 'girl', 'lady', 'ì—¬ì„±', 'ì—¬ì']):
            final_gender = 'Female'
        elif any(x in raw_gender.lower() for x in ['man', 'male', 'boy', 'ë‚¨ì„±', 'ë‚¨ì']):
            final_gender = 'Male'
        else:
            final_gender = 'Unisex'

        try:
            raw_price = str(product_data.get("price", 0))
            price = int(re.sub(r"[^0-9]", "", raw_price))
        except:
            price = 0

        # ë²¡í„° ìƒì„±
        meta_text = f"[{final_gender}] {final_name} {final_cat} {final_desc}"
        vector = model_engine.generate_embedding(meta_text)

        logger.info(f"âœ… Analysis Success: {final_name} ({final_gender}) - {price}ì›")

        return {
            "name": final_name,
            "category": final_cat,
            "gender": final_gender,
            "description": final_desc,
            "price": price,
            "vector": vector
        }

    except Exception as e:
        logger.error(f"âŒ Analysis Critical Error: {e}")
        return {
            "name": f"ë“±ë¡ëœ ìƒí’ˆ ({filename})",
            "category": "Etc",
            "gender": "Unisex",
            "description": "ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨.",
            "price": 0,
            "vector": [0.0] * 768
        }

@api_router.post("/llm-generate-response")
async def llm_generate(body: Dict[str, str]):
    prompt = body.get("prompt", "")
    try:
        korean_prompt = f"ì§ˆë¬¸: {prompt}\në‹µë³€ (í•œêµ­ì–´):"
        answer = model_engine.generate_text(korean_prompt)
        return {"answer": answer}
    except:
        return {"answer": "ì£„ì†¡í•©ë‹ˆë‹¤. AI ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

@api_router.post("/determine-path")
async def determine_path(request: PathRequest):
    return {"path": "INTERNAL"}

@api_router.post("/process-internal", response_model=SearchProcessResponse)
async def process_internal(request: InternalSearchRequest):
    query = request.query
    vector = model_engine.generate_embedding(query)
    return {"vector": vector, "reason": f"'{query}' ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤."}

@api_router.post("/process-external", response_model=SearchProcessResponse)
async def process_external(request: InternalSearchRequest):
    return await process_internal(request)

app.include_router(api_router)

@app.get("/")
def read_root():
    return {"message": "Modify AI Service is Running"}