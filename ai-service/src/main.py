import logging
import json
import re
import base64
import os
import uuid
import traceback
from fastapi import FastAPI, HTTPException, APIRouter, UploadFile, File
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
from contextlib import asynccontextmanager

from src.core.model_engine import model_engine
from src.core.prompts import VISION_ANALYSIS_PROMPT
from src.services.rag_orchestrator import rag_orchestrator

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("ai-service")

@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info("ğŸš€ AI Service Starting...")
    try:
        model_engine.initialize()
    except Exception as e:
        logger.error(f"âš ï¸ Model init warning: {e}")
    yield
    logger.info("ğŸ’¤ AI Service Shutting down...")

app = FastAPI(title="Modify AI Service", version="1.0.0", lifespan=lifespan)
api_router = APIRouter(prefix="/api/v1")

# --- DTO ---
class EmbedRequest(BaseModel):
    text: str

class AnalyzeRequest(BaseModel):
    image_b64: str
    query: str   

class EmbedResponse(BaseModel):
    vector: List[float]

class ImageAnalysisResponse(BaseModel):
    name: str
    category: str
    gender: str
    description: str
    price: int
    vector: List[float]           # BERT (768)
    vector_clip: List[float]      # CLIP Full (512)
    vector_clip_upper: List[float] # CLIP Upper (512)
    vector_clip_lower: List[float] # CLIP Lower (512)
class PathRequest(BaseModel):
    query: str

class InternalSearchRequest(BaseModel):
    query: str
    image_b64: Optional[str] = None

# CLIP ë²¡í„° ìƒì„± ìš”ì²­
class ClipVectorRequest(BaseModel):
    image_b64: str

class ClipVectorResponse(BaseModel):
    vector: List[float]
    dimension: int

# ì´ë¯¸ì§€ ê¸°ë°˜ ìƒí’ˆ ê²€ìƒ‰ ìš”ì²­
class ImageSearchRequest(BaseModel):
    image_b64: str
    limit: int = 12

# --- Helper Methods (ê¸°ì¡´ ì½”ë“œ ìœ ì§€) ---

def _fix_encoding(text: str) -> str:
    """
    [í•µì‹¬] ê¹¨ì§„ í•œê¸€(Mojibake) ë° ìœ ë‹ˆì½”ë“œ ì´ìŠ¤ì¼€ì´í”„ ì™„ë²½ ë³µêµ¬
    """
    if not text:
        return ""

    # 1. Mojibake ë³µêµ¬ ì‹œë„ (Latin-1 -> UTF-8)
    try:
        fixed = text.encode('latin1').decode('utf-8')
        return fixed
    except Exception:
        pass

    # 2. ìœ ë‹ˆì½”ë“œ ì´ìŠ¤ì¼€ì´í”„ ë³µêµ¬ ì‹œë„
    try:
        return text.encode('utf-8').decode('unicode_escape')
    except Exception:
        pass
        
    return text

def _extract_from_text(text: str, key_patterns: List[str], default: str = "") -> str:
    """JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì •ê·œì‹ ì¶”ì¶œ + ì¸ì½”ë”© ìë™ ë³´ì •"""
    for pattern in key_patterns:
        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
        if match:
            clean_val = match.group(1).strip().strip('",').strip()
            return _fix_encoding(clean_val)
    return default

CATEGORY_MAP = {
    # AIê°€ ë±‰ì„ ìˆ˜ ìˆëŠ” í•œê¸€ -> DBì— ì €ì¥í•  ì˜ì–´ í‘œì¤€
    "ìƒì˜": "Tops",
    "í‹°ì…”ì¸ ": "Tops",
    "ë‹ˆíŠ¸": "Tops",
    "ì…”ì¸ ": "Tops",
    
    "í•˜ì˜": "Bottoms",
    "ë°”ì§€": "Bottoms",
    "ì¹˜ë§ˆ": "Bottoms",
    "ìŠ¤ì»¤íŠ¸": "Bottoms",
    "íŒ¬ì¸ ": "Bottoms",
    "ì§„": "Bottoms",
    
    "ì•„ìš°í„°": "Outerwear",
    "ìì¼“": "Outerwear",
    "ì½”íŠ¸": "Outerwear",
    "íŒ¨ë”©": "Outerwear",
    
    "ì›í”¼ìŠ¤": "Dresses",
    "ë“œë ˆìŠ¤": "Dresses",
    
    "ì‹ ë°œ": "Shoes",
    "ìŠˆì¦ˆ": "Shoes",
    
    "ì•¡ì„¸ì„œë¦¬": "Accessories",
    "ëª¨ì": "Accessories",
    "ê°€ë°©": "Accessories"
}

# --- Endpoints (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€) ---

@api_router.post("/embed-text", response_model=EmbedResponse)
async def embed_text(request: EmbedRequest):
    try:
        vector = model_engine.generate_embedding(request.text)
        return {"vector": vector}
    except:
        return {"vector": [0.0] * 768} 

@api_router.post("/analyze-image", response_model=ImageAnalysisResponse)
async def analyze_image(file: UploadFile = File(...)):
    filename = file.filename
    try:
        contents = await file.read()
        image_b64 = base64.b64encode(contents).decode("utf-8")
        
        logger.info(f"ğŸ‘ï¸ Analyzing image: {filename}...")
        
        # 1. Text Generation (Llama)
        generated_text = model_engine.generate_with_image(VISION_ANALYSIS_PROMPT, image_b64)
        
        # JSON Parsing (ì´ë¯¸ model_engine ë‚´ë¶€ì—ì„œ ì¸ì½”ë”©/íŒŒì‹± ì²˜ë¦¬ë¨)
        try:
            product_data = json.loads(generated_text)
        except:
            product_data = {
                "name": f"ìƒí’ˆ {filename}", 
                "category": "Fashion", 
                "price": 0, 
                "gender": "Unisex", 
                "description": generated_text[:200]
            }

        # ---------------------------------------------------------
        # í•œê¸€ ì¹´í…Œê³ ë¦¬ë¥¼ ì˜ì–´ í‘œì¤€(Enum)ìœ¼ë¡œ ë³€í™˜
        # ---------------------------------------------------------
        raw_category = product_data.get("category", "Etc") # AIê°€ ì¤€ ê°’ (ì˜ˆ: "ì•„ìš°í„°")
        
        # 1. ë§¤í•‘ í…Œì´ë¸”ì—ì„œ ì°¾ê¸°
        standard_category = CATEGORY_MAP.get(raw_category)
        
        # 2. ëª» ì°¾ì•˜ë‹¤ë©´, í˜¹ì‹œ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ìœ ì—°ì„± í™•ë³´)
        if not standard_category:
            for kr_key, en_val in CATEGORY_MAP.items():
                if kr_key in raw_category: # ì˜ˆ: "ë©‹ì§„ ì•„ìš°í„°" -> "Outerwear"
                    standard_category = en_val
                    break
        
        # 3. ê·¸ë˜ë„ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ í˜¹ì€ ì›ë³¸ ì‚¬ìš© (ë‹¨, ì›ë³¸ì´ ì˜ì–´ì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ)
        final_category = standard_category if standard_category else "Etc"
        
        # ë³€í™˜ëœ ì¹´í…Œê³ ë¦¬ë¥¼ ë®ì–´ì”Œì›€
        product_data["category"] = final_category
        
        logger.info(f"ğŸ”„ Category Mapped: '{raw_category}' -> '{final_category}'")
        # ---------------------------------------------------------    

        # 2. Vector Generation (BERT + CLIP Full/Upper/Lower)
        # BERT (768)
        meta_text = f"[{product_data.get('gender')}] {product_data.get('name')} {product_data.get('category')}"
        vector_bert = model_engine.generate_embedding(meta_text)
        
        # CLIP (512 x 3) - Optimized & Zero-padded safe
        fashion_vectors = model_engine.generate_fashion_embeddings(image_b64)
        
        logger.info(f"âœ… Analysis Success: {product_data.get('name')}")
        
        return {
            "name": product_data.get("name", "Unknown"),
            "category": product_data.get("category", "Etc"),
            "gender": product_data.get("gender", "Unisex"),
            "description": product_data.get("description", ""),
            "price": product_data.get("price", 0),
            "vector": vector_bert,
            "vector_clip": fashion_vectors["full"],
            "vector_clip_upper": fashion_vectors["upper"],
            "vector_clip_lower": fashion_vectors["lower"]
        }

    except Exception as e:
        logger.error(f"âŒ Analysis Critical Error: {e}")
        # Error Fallback (DB Insertë¥¼ ìœ„í•´ ëª¨ë“  ë²¡í„° 0 ì±„ì›€)
        zero_512 = [0.0] * 512
        return {
            "name": f"ErrorItem ({filename})",
            "category": "Error",
            "gender": "Unisex",
            "description": "ë¶„ì„ ì‹¤íŒ¨",
            "price": 0,
            "vector": [0.0] * 768,
            "vector_clip": zero_512,
            "vector_clip_upper": zero_512,
            "vector_clip_lower": zero_512
        }

@api_router.post("/llm-generate-response")
async def llm_generate(body: Dict[str, str]):
    prompt = body.get("prompt", "")
    logger.info(f"ğŸ“ LLM Prompt received: {prompt[:100]}...")
    try:
        korean_prompt = f"ì§ˆë¬¸: {prompt}\në‹µë³€ (í•œêµ­ì–´):"
        answer = model_engine.generate_text(korean_prompt)
        return {"answer": answer}
    except Exception as e:
        logger.error(f"âŒ LLM Generation Failed: {e}")
        logger.error(traceback.format_exc())
        return {"answer": "ì£„ì†¡í•©ë‹ˆë‹¤. AI ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
@api_router.post("/analyze-image-detail")
async def analyze_image_detail(req: AnalyzeRequest):
    """íŠ¹ì • ì´ë¯¸ì§€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ ìš”ì²­ (RAGìš© - base64 ì´ë¯¸ì§€)"""
    result = await rag_orchestrator.analyze_specific_image(req.image_b64, req.query)
    return {"analysis": result}    


# -------------------------------------------------------------
# CLIP ì´ë¯¸ì§€ ë²¡í„° ìƒì„± ì—”ë“œí¬ì¸íŠ¸
# -------------------------------------------------------------

@api_router.post("/generate-clip-vector", response_model=ClipVectorResponse)
async def generate_clip_vector(request: ClipVectorRequest):
    """
    ì´ë¯¸ì§€ì—ì„œ CLIP ë²¡í„°(512ì°¨ì›) ìƒì„±
    - í›„ë³´ ì´ë¯¸ì§€ í´ë¦­ ì‹œ ìƒí’ˆ ì¬ê²€ìƒ‰ì— ì‚¬ìš©
    - ìƒí’ˆ ë“±ë¡ ì‹œ CLIP ë²¡í„° ì €ì¥ì— ì‚¬ìš©
    """
    try:
        image_b64 = request.image_b64
        
        # data:image/... í˜•ì‹ì´ë©´ base64 ë¶€ë¶„ë§Œ ì¶”ì¶œ
        if "base64," in image_b64:
            image_b64 = image_b64.split("base64,")[1]
        
        # CLIP Vision ëª¨ë¸ë¡œ ë²¡í„° ìƒì„± (YOLO ì ìš©)
        result = model_engine.generate_image_embedding(image_b64, use_yolo=True)
        clip_vector = result.get("clip", [])
        
        if not clip_vector or len(clip_vector) == 0:
            raise HTTPException(status_code=500, detail="CLIP ë²¡í„° ìƒì„± ì‹¤íŒ¨")
        
        logger.info(f"âœ… CLIP vector generated: {len(clip_vector)} dimensions")
        
        return {
            "vector": clip_vector,
            "dimension": len(clip_vector)
        }
        
    except Exception as e:
        logger.error(f"âŒ CLIP vector generation failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# âœ… NEW: íŒ¨ì…˜ íŠ¹í™” CLIP ë²¡í„° ìƒì„± (YOLO + ìƒì˜/í•˜ì˜ ë¶„ë¦¬)
class FashionClipRequest(BaseModel):
    image_b64: str
    target: str = "full"  # "full", "upper", "lower"


@api_router.post("/generate-fashion-clip-vector")
async def generate_fashion_clip_vector(request: FashionClipRequest):
    """
    âœ… íŒ¨ì…˜ íŠ¹í™” CLIP ë²¡í„° ìƒì„±
    - YOLOë¡œ ì‚¬ëŒ/ì˜· ì˜ì—­ ê°ì§€ í›„ í¬ë¡­
    - target: "full"(ì „ì‹ ), "upper"(ìƒì˜), "lower"(í•˜ì˜)
    """
    try:
        image_b64 = request.image_b64
        target = request.target
        
        # data:image/... í˜•ì‹ì´ë©´ base64 ë¶€ë¶„ë§Œ ì¶”ì¶œ
        if "base64," in image_b64:
            image_b64 = image_b64.split("base64,")[1]
        
        # PIL Imageë¡œ ë³€í™˜
        import io
        from PIL import Image
        pil_image = Image.open(io.BytesIO(base64.b64decode(image_b64)))
        
        # YOLOë¡œ ì˜ì—­ í¬ë¡­ í›„ CLIP ë²¡í„° ìƒì„±
        try:
            from src.core.yolo_detector import yolo_detector
            
            # YOLO ì´ˆê¸°í™”
            if not yolo_detector.initialized:
                yolo_detector.initialize()
            
            # ì§€ì •ëœ ì˜ì—­ í¬ë¡­
            cropped = yolo_detector.crop_fashion_regions(pil_image, target=target)
            
            if cropped is not None:
                logger.info(f"âœ‚ï¸ YOLO cropped '{target}' region: {cropped.size}")
                pil_image = cropped

                # âœ… [DEBUG] í¬ë¡­ëœ ì´ë¯¸ì§€ê°€ ë§ëŠ”ì§€ ëˆˆìœ¼ë¡œ í™•ì¸í•˜ê¸° ìœ„í•´ ì €ì¥!
                debug_dir = "/app/static/debug" # ë„ì»¤ ë³¼ë¥¨ ê²½ë¡œ í™•ì¸ í•„ìš” (í˜¹ì€ "./debug_images")
                os.makedirs(debug_dir, exist_ok=True)
                debug_filename = f"{debug_dir}/{uuid.uuid4()}_{target}.jpg"
                pil_image.save(debug_filename)
                logger.info(f"ğŸ“¸ Debug Image Saved: {debug_filename}")


            else:
                logger.warning(f"âš ï¸ YOLO crop failed for '{target}', using original")
                
        except ImportError as e:
            logger.warning(f"âš ï¸ YOLO not available: {e}")
        except Exception as e:
            logger.warning(f"âš ï¸ YOLO failed: {e}")
        
        # CLIP ë²¡í„° ìƒì„± (YOLO ì¤‘ë³µ ì ìš© ë°©ì§€)
        result = model_engine.generate_image_embedding(pil_image, use_yolo=False)
        clip_vector = result.get("clip", [])
        
        if not clip_vector or len(clip_vector) == 0:
            raise HTTPException(status_code=500, detail="CLIP ë²¡í„° ìƒì„± ì‹¤íŒ¨")
        
        logger.info(f"âœ… Fashion CLIP vector generated ({target}): {len(clip_vector)} dimensions")
        
        return {
            "vector": clip_vector,
            "dimension": len(clip_vector),
            "target": target
        }
        
    except Exception as e:
        logger.error(f"âŒ Fashion CLIP vector generation failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@api_router.post("/search-by-image")
async def search_by_image(request: ImageSearchRequest):
    """
    ì´ë¯¸ì§€ ê¸°ë°˜ ìƒí’ˆ ê²€ìƒ‰
    - í›„ë³´ ì´ë¯¸ì§€ í´ë¦­ ì‹œ í˜¸ì¶œ
    - ì´ë¯¸ì§€ â†’ CLIP ë²¡í„° â†’ ìœ ì‚¬ ìƒí’ˆ ê²€ìƒ‰
    """
    try:
        image_b64 = request.image_b64
        
        if "base64," in image_b64:
            image_b64 = image_b64.split("base64,")[1]
        
        # CLIP ë²¡í„° ìƒì„±
        result = model_engine.generate_image_embedding(image_b64)
        clip_vector = result.get("clip", [])
        
        if not clip_vector:
            raise HTTPException(status_code=500, detail="CLIP ë²¡í„° ìƒì„± ì‹¤íŒ¨")
        
        logger.info(f"ğŸ–¼ï¸ Image search: CLIP vector generated ({len(clip_vector)} dims)")
        
        return {
            "vectors": {
                "clip": clip_vector,
                "bert": None
            },
            "search_type": "image_similarity"
        }
        
    except Exception as e:
        logger.error(f"âŒ Image search failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# -------------------------------------------------------------
#  RAG Orchestrator ì—°ê²° (ê²€ìƒ‰ ë¡œì§ ê³ ë„í™”)
# -------------------------------------------------------------

@api_router.post("/determine-path")
async def determine_path(request: PathRequest):
    """
    ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ê²½ë¡œ(INTERNAL vs EXTERNAL)ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    """
    logger.info(f"ğŸ¤” Determining path for query: {request.query}")
    try:
        decision = await rag_orchestrator.determine_search_path(request.query)
        logger.info(f"ğŸ‘‰ Decision: {decision}")
        return {"path": decision}
    except Exception as e:
        logger.error(f"Determine path error: {e}")
        return {"path": "INTERNAL"}

@api_router.post("/process-internal")
async def process_internal(request: InternalSearchRequest):
    """
    ë‚´ë¶€ ê²€ìƒ‰ ë¡œì§ ì‹¤í–‰
    """
    logger.info(f"ğŸ¢ Processing Internal (Orchestrator): {request.query}")
    return await rag_orchestrator.process_internal_search(request.query)

@api_router.post("/process-external")
async def process_external(request: InternalSearchRequest):
    """
    ì™¸ë¶€(Google+RAG) ê²€ìƒ‰ ë¡œì§ ì‹¤í–‰
    """
    logger.info(f"ğŸŒ Processing External (Orchestrator): {request.query}")
    try:
        result = await rag_orchestrator.process_external_rag(request.query)
        return result
    except Exception as e:
        logger.error(f"External processing failed: {e}")
        return await rag_orchestrator.process_internal_search(request.query)

app.include_router(api_router)

@app.get("/")
def read_root():
    return {"message": "Modify AI Service is Running"}