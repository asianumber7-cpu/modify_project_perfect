

import asyncio
import logging
import aiohttp
import base64
import re
from io import BytesIO
from typing import List, Dict, Any, Optional
from PIL import Image

from src.core.model_engine import model_engine
from src.services.quota_monitor import quota_monitor
from src.services.google_search_client import GoogleSearchClient

logger = logging.getLogger(__name__)

class AIOrchestrator:
    def __init__(self):
        self.engine = model_engine
        self.search_client = GoogleSearchClient()
        self.semaphore = asyncio.Semaphore(5)
        
        # âœ… í™•ì¥ëœ ì™¸ë¶€ ê²€ìƒ‰ íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ
        self.external_triggers = [
            # íŒ¨ì…˜ ê´€ë ¨
            "ìŠ¤íƒ€ì¼", "ì½”ë””", "íŒ¨ì…˜", "ë£©", "ìœ í–‰", "íŠ¸ë Œë“œ",
            # ì—°ì˜ˆì¸/ì¸ë¬¼ ê´€ë ¨
            "ì—°ì˜ˆì¸", "ê³µí•­", "ì…ì€", "ì°©ìš©", "ì˜·", "ì˜ìƒ",
            # í–‰ë™ ê´€ë ¨
            "ì¶”ì²œ", "ë³´ì—¬ì¤˜", "ì°¾ì•„ì¤˜", "ì•Œë ¤ì¤˜",
            # ì˜ì–´ í‚¤ì›Œë“œ
            "style", "fashion", "look", "outfit", "wear"
        ]
        
        # âœ… í•œê¸€ ì´ë¦„ íŒ¨í„´ (2-4ê¸€ì í•œê¸€ ì´ë¦„)
        self.korean_name_pattern = re.compile(r'[ê°€-í£]{2,4}')

    async def _download_image(self, session: aiohttp.ClientSession, url: str) -> Optional[Image.Image]:
        async with self.semaphore:
            try:
                timeout = aiohttp.ClientTimeout(total=4)
                headers = {
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                    "Referer": "https://www.google.com/"
                }
                async with session.get(url, headers=headers, timeout=timeout) as response:
                    if response.status == 200:
                        data = await response.read()
                        image = Image.open(BytesIO(data)).convert("RGB")
                        if image.width < 250 or image.height < 250: return None
                        return image
            except Exception as e:
                logger.debug(f"Image download failed: {url} - {e}")
                return None
        return None

    def _image_to_base64(self, image: Image.Image) -> str:
        try:
            buffered = BytesIO()
            image.save(buffered, format="JPEG", quality=95)
            img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
            return f"data:image/jpeg;base64,{img_str}"
        except Exception: return ""

    def _optimize_query(self, user_query: str) -> str:
        """ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™” - í•œê¸€ ì´ë¦„ ë³´ì¡´"""
        # ë¶ˆìš©ì–´ ëª©ë¡
        stop_words = [
            "ì¶”ì²œí•´ì¤˜", "ë³´ì—¬ì¤˜", "ì°¾ì•„ì¤˜", "ì•Œë ¤ì¤˜", "ì–´ë•Œ", 
            "ì‚¬ì§„", "ì´ë¯¸ì§€", "10ë¶„ë§Œì—", "ê¼¬ì…¨ë˜", "ì¢€", "í•´ì¤˜",
            "ë­", "ì–´ë””", "ëˆ„êµ¬", "ì–¸ì œ", "ì–´ë–»ê²Œ"
        ]
        
        words = user_query.split()
        keywords = []
        
        for w in words:
            # ì¡°ì‚¬ ì œê±°
            clean_w = re.sub(r'(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì˜|ì—|ë¡œ|ìœ¼ë¡œ|ì™€|ê³¼|ë„|ë§Œ|ê¹Œì§€|ë¶€í„°)$', '', w)
            
            # ë¶ˆìš©ì–´ ì²´í¬
            if clean_w in stop_words:
                continue
            
            # ìµœì†Œ ê¸¸ì´ ì²´í¬
            if len(clean_w) < 2:
                continue
                
            keywords.append(clean_w)
        
        if not keywords:
            return user_query
            
        # íŒ¨ì…˜ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ê°€ (ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ)
        optimized = " ".join(keywords)
        if "íŒ¨ì…˜" not in optimized and "ìŠ¤íƒ€ì¼" not in optimized:
            optimized += " íŒ¨ì…˜ ìŠ¤íƒ€ì¼"
            
        logger.info(f"ğŸ” Query optimized: '{user_query}' -> '{optimized}'")
        return optimized

    def _get_scoring_context(self, query: str) -> str:
        if any(k in query for k in ["ê°€ë°©", "ì‹ ë°œ", "ì§€ê°‘", "ì•¡ì„¸ì„œë¦¬"]): 
            return "close up product shot"
        return "full body fashion style"

    def _normalize_score(self, raw_score: float) -> int:
        if raw_score < 0.15: return 0
        normalized = (raw_score - 0.15) * 450
        return int(min(max(normalized, 60), 99))

    async def process_external_rag(self, query: str) -> Dict[str, Any]:
        """ì™¸ë¶€ ì´ë¯¸ì§€ ê²€ìƒ‰ + VLM ë¶„ì„"""
        logger.info(f"ğŸŒ Processing EXTERNAL RAG: {query}")
        
        # ì¿¼í„° ì²´í¬
        allowed, reason = quota_monitor.check_and_increment()
        if not allowed:
            logger.warning(f"âš ï¸ Quota exceeded: {reason}")
            return await self.process_internal_search(query)

        optimized_query = self._optimize_query(query)
        
        # Google ì´ë¯¸ì§€ ê²€ìƒ‰
        logger.info(f"ğŸ” Searching Google Images: '{optimized_query}'")
        search_results = await self.search_client.search_images(
            optimized_query, num_results=15, start_index=1
        )
        
        if not search_results:
            logger.warning("âŒ No search results from Google")
            return await self.process_internal_search(query)
            
        logger.info(f"âœ… Found {len(search_results)} images")

        best_image = None
        candidates_data = []

        async with aiohttp.ClientSession() as session:
            tasks = [self._download_image(session, item['link']) for item in search_results]
            downloaded_images = await asyncio.gather(*tasks)

            scored_candidates = []
            clip_prompt = f"{optimized_query} {self._get_scoring_context(optimized_query)}"

            for i, img in enumerate(downloaded_images):
                if img:
                    base_score = self.engine.calculate_similarity(clip_prompt, img)
                    ratio_bonus = 0.05 if img.height > img.width else 0.0
                    final_score = base_score + ratio_bonus

                    if final_score > 0.18:
                        scored_candidates.append({
                            "image": img,
                            "url": search_results[i]['link'],
                            "raw_score": final_score,
                            "display_score": self._normalize_score(final_score)
                        })

            scored_candidates.sort(key=lambda x: x['raw_score'], reverse=True)
            top_candidates = scored_candidates[:4]

            if top_candidates:
                best_candidate = top_candidates[0]
                best_image = best_candidate['image']
                
                for cand in top_candidates:
                    candidates_data.append({
                        "image_base64": self._image_to_base64(cand['image']),
                        "score": cand['display_score']
                    })
                    
        logger.info(f"ğŸ“Š Valid candidates: {len(scored_candidates)}")

        if not best_image:
            logger.warning("âŒ No valid images after scoring")
            return await self.process_internal_search(query)

        summary = await self._analyze_image_with_vlm(best_image, query)
        final_data_uri = self._image_to_base64(best_image)

        vectors = {
            "bert": self.engine.generate_dual_embedding(summary)["bert"],
            "clip": self.engine.generate_image_embedding(best_image)["clip"]
        }

        return {
            "vectors": vectors,
            "search_path": "EXTERNAL",
            "strategy": "visual_rag_vlm",
            "ai_analysis": {
                "summary": summary,
                "reference_image": final_data_uri,
                "candidates": candidates_data
            },
            "description": summary,
            "ref_image": final_data_uri
        }

    async def analyze_specific_image(self, image_b64: str, query: str) -> str:
        try:
            if "base64," in image_b64:
                image_b64 = image_b64.split("base64,")[1]
            return await self._analyze_image_with_vlm(image_b64, query)
        except Exception:
            return "ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

    async def _analyze_image_with_vlm(self, image_data: Any, query: str) -> str:
        """VLMì„ ì´ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„"""
        try:
            if isinstance(image_data, Image.Image):
                img_b64 = self._image_to_base64(image_data).split(",")[1]
            else:
                img_b64 = image_data

            vlm_prompt = f"""
            ë‹¹ì‹ ì€ ì •ì§í•œ íŒ¨ì…˜ ì—ë””í„°ì…ë‹ˆë‹¤.
            **ì˜¤ì§ ì´ë¯¸ì§€ì— ì‹œê°ì ìœ¼ë¡œ ë³´ì´ëŠ” ê²ƒë§Œ** ì„¤ëª…í•˜ì„¸ìš”. 
            ì´ë¯¸ì§€ì— ì—†ëŠ” ë‚´ìš©(ìƒìƒ, ë°°ê²½ì§€ì‹, ì¶”ì¸¡)ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
            
            ì‚¬ìš©ì ì§ˆë¬¸: "{query}" (ì°¸ê³ ìš©ì¼ ë¿, ì‹¤ì œ ì´ë¯¸ì§€ ë‚´ìš©ì´ ìš°ì„ ì…ë‹ˆë‹¤.)
            
            [ë¶„ì„ ê°€ì´ë“œ]
            1. **íŠ¸ë Œë“œ ë¬´ë“œ**: ì´ë¯¸ì§€ì—ì„œ ëŠê»´ì§€ëŠ” ì‹¤ì œ ë¶„ìœ„ê¸°ë§Œ í•œ ì¤„ë¡œ ì‘ì„±.
            2. **ìŠ¤íƒ€ì¼ë§ í¬ì¸íŠ¸**: ëˆˆì— ë³´ì´ëŠ” ì˜·ì˜ ìƒ‰ìƒ, ì†Œì¬, í•ì„ êµ¬ì²´ì ìœ¼ë¡œ ë¬˜ì‚¬ (ì˜ˆ: "ê²€ì€ìƒ‰ ê°€ì£½ ìì¼“", "íŒŒë€ìƒ‰ ë°ë‹˜ íŒ¬ì¸ ").
            3. **ì¶”ì²œ ì•„ì´í…œ**: ì´ ì‚¬ì§„ ì† ì¸ë¬¼ì´ ì°©ìš©í•œ ì•„ì´í…œê³¼ ìœ ì‚¬í•œ ì œí’ˆ ì¶”ì²œ.
            
            ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
            """
            return self.engine.generate_with_image(vlm_prompt, img_b64)
        except Exception as e:
            logger.error(f"VLM analysis failed: {e}")
            return "ë¶„ì„ ë¶ˆê°€"

    async def process_internal_search(self, query: str) -> Dict[str, Any]:
        """ë‚´ë¶€ í…ìŠ¤íŠ¸ ê²€ìƒ‰"""
        logger.info(f"ğŸ“¦ Processing INTERNAL search: {query}")
        vectors = self.engine.generate_dual_embedding(query)
        return {
            "vectors": vectors,
            "search_path": "INTERNAL",
            "strategy": "internal_text",
            "ai_analysis": None,
            "description": f"'{query}' ë‚´ë¶€ ê²€ìƒ‰ ê²°ê³¼",
            "ref_image": None
        }

    async def determine_search_path(self, query: str) -> str:
        """
        âœ… ìˆ˜ì •: ì™¸ë¶€ ê²€ìƒ‰ íŠ¸ë¦¬ê±° ì¡°ê±´ í™•ì¥
        - íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ í¬í•¨ ì‹œ EXTERNAL
        - í•œê¸€ ì´ë¦„(2-4ê¸€ì) + íŒ¨ì…˜ ê´€ë ¨ í‚¤ì›Œë“œ ì¡°í•© ì‹œ EXTERNAL
        """
        query_lower = query.lower()
        
        # 1. ê¸°ë³¸ íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ ì²´í¬
        if any(t in query_lower for t in self.external_triggers):
            logger.info(f"ğŸ¯ External trigger found in: '{query}'")
            return 'EXTERNAL'
        
        # 2. í•œê¸€ ì´ë¦„ + íŒ¨ì…˜ ê´€ë ¨ ë‹¨ì–´ ì¡°í•© ì²´í¬
        korean_names = self.korean_name_pattern.findall(query)
        fashion_keywords = ["íŒ¨ì…˜", "ìŠ¤íƒ€ì¼", "ì½”ë””", "ë£©", "ì˜·", "ì°©ìš©", "ê³µí•­", "ì…ì€"]
        
        if korean_names and any(k in query for k in fashion_keywords):
            logger.info(f"ğŸ¯ Korean name + fashion keyword found: '{query}' (names: {korean_names})")
            return 'EXTERNAL'
        
        # 3. ìœ ëª…ì¸ ì´ë¦„ íŒ¨í„´ (ì´ë¦„ + íŒ¨ì…˜/ìŠ¤íƒ€ì¼/ê³µí•­ ë“±)
        celebrity_patterns = [
            r'[ê°€-í£]{2,4}\s*(íŒ¨ì…˜|ìŠ¤íƒ€ì¼|ì½”ë””|ë£©|ì˜·|ê³µí•­|ì°©ì¥|ì˜ìƒ)',
            r'(ì‹ ì„¸ê²½|ì œë‹ˆ|ì§€ìˆ˜|ë¡œì œ|ë¦¬ì‚¬|ì•„ì´ìœ |ìˆ˜ì§€|ì†¡í˜œêµ|ê¹€íƒœë¦¬|í•œì†Œí¬|ì°¨ì€ìš°|ë·”|ì •êµ­|ì§€ë¯¼).*'
        ]
        
        for pattern in celebrity_patterns:
            if re.search(pattern, query):
                logger.info(f"ğŸ¯ Celebrity pattern matched: '{query}'")
                return 'EXTERNAL'
        
        logger.info(f"ğŸ“¦ No external trigger, using INTERNAL: '{query}'")
        return 'INTERNAL'

rag_orchestrator = AIOrchestrator()