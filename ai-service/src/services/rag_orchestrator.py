import asyncio
import logging
import aiohttp
import base64
import re
from io import BytesIO
from typing import List, Dict, Any, Optional
from PIL import Image

from src.core.model_engine import model_engine
from src.services.quota_monitor import quota_monitor
from src.services.google_search_client import GoogleSearchClient

logger = logging.getLogger(__name__)

class AIOrchestrator:
    def __init__(self):
        self.engine = model_engine
        self.search_client = GoogleSearchClient()
        self.semaphore = asyncio.Semaphore(5)

    async def _download_image(self, session: aiohttp.ClientSession, url: str) -> Optional[Image.Image]:
        async with self.semaphore:
            try:
                timeout = aiohttp.ClientTimeout(total=4)
                headers = {
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                    "Referer": "https://www.google.com/"
                }
                async with session.get(url, headers=headers, timeout=timeout) as response:
                    if response.status == 200:
                        data = await response.read()
                        image = Image.open(BytesIO(data)).convert("RGB")
                        if image.width < 250 or image.height < 250: return None
                        return image
            except Exception: return None
        return None

    # [ìˆ˜ì •] í™”ì§ˆ ê°œì„  (85 -> 95)
    def _image_to_base64(self, image: Image.Image) -> str:
        try:
            buffered = BytesIO()
            # [í•µì‹¬] VLMì´ ë””í…Œì¼ì„ ë³¼ ìˆ˜ ìˆë„ë¡ ê³ í™”ì§ˆ ìœ ì§€
            image.save(buffered, format="JPEG", quality=95)
            img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
            return f"data:image/jpeg;base64,{img_str}"
        except Exception: return ""

    def _optimize_query(self, user_query: str) -> str:
        # (ê¸°ì¡´ ì½”ë“œ ìœ ì§€: ì¡°ì‚¬ ì œê±° ë° LLM ìµœì í™”)
        prompt = f"""
        Role: Search Query Optimizer.
        Task: Convert natural language to short keywords.
        Input: "{user_query}"
        
        Rules:
        1. Remove Particles: Remove Korean particles like 'ê°€', 'ëŠ”', 'ì„', 'ë¥¼'.
        2. Remove Context: Remove "10ë¶„ë§Œì—", "ê¼¬ì‹ ", "ë‚¨ì".
        3. Output: "Celebrity Name" + "Style Keywords" (e.g. "Lee Hyori Y2K Fashion").
        """
        try:
            optimized = self.engine.generate_text(prompt).strip()
            if len(optimized) < 30 and len(optimized) > 2:
                return optimized
        except: pass

        words = user_query.split()
        keywords = []
        stop_words = ["ì¶”ì²œí•´ì¤˜", "ë³´ì—¬ì¤˜", "ì°¾ì•„ì¤˜", "ì•Œë ¤ì¤˜", "ì–´ë•Œ", "ì‚¬ì§„", "ì´ë¯¸ì§€", "10ë¶„ë§Œì—", "ê¼¬ì…¨ë˜", "ë‚¨ì"]
        
        for w in words:
            clean_w = re.sub(r'(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì˜|ì—|ë¡œ)$', '', w)
            if clean_w not in stop_words and len(clean_w) > 1:
                keywords.append(clean_w)
        
        if not keywords: return user_query
        return " ".join(keywords)

    def _get_scoring_context(self, query: str) -> str:
        if any(k in query for k in ["ê°€ë°©", "ì‹ ë°œ", "ì§€ê°‘"]): return "close up product shot"
        return "full body fashion style"

    def _normalize_score(self, raw_score: float) -> int:
        if raw_score < 0.15: return 0
        normalized = (raw_score - 0.15) * 450
        return int(min(max(normalized, 60), 99))

    async def process_external_rag(self, query: str) -> Dict[str, Any]:
        logger.info(f"ğŸŒ Processing EXTERNAL RAG: {query}")
        allowed, _ = quota_monitor.check_and_increment()
        if not allowed: return await self.process_internal_search(query)

        optimized_query = self._optimize_query(query)
        
        search_results = await self.search_client.search_images(
            optimized_query, num_results=15, start_index=1
        )
        
        if not search_results: return await self.process_internal_search(query)

        best_image = None
        candidates_data = []

        async with aiohttp.ClientSession() as session:
            tasks = [self._download_image(session, item['link']) for item in search_results]
            downloaded_images = await asyncio.gather(*tasks)

            scored_candidates = []
            clip_prompt = f"{optimized_query} {self._get_scoring_context(optimized_query)}"

            for i, img in enumerate(downloaded_images):
                if img:
                    base_score = self.engine.calculate_similarity(clip_prompt, img)
                    ratio_bonus = 0.05 if img.height > img.width else 0.0
                    final_score = base_score + ratio_bonus

                    if final_score > 0.18:
                        scored_candidates.append({
                            "image": img,
                            "url": search_results[i]['link'],
                            "raw_score": final_score,
                            "display_score": self._normalize_score(final_score)
                        })

            scored_candidates.sort(key=lambda x: x['raw_score'], reverse=True)
            top_candidates = scored_candidates[:4]

            if top_candidates:
                best_candidate = top_candidates[0]
                best_image = best_candidate['image']
                
                for cand in top_candidates:
                    candidates_data.append({
                        "image_base64": self._image_to_base64(cand['image']),
                        "score": cand['display_score']
                    })

        if not best_image:
            return await self.process_internal_search(query)

        summary = await self._analyze_image_with_vlm(best_image, query)
        final_data_uri = self._image_to_base64(best_image)

        vectors = {
            "bert": self.engine.generate_dual_embedding(summary)["bert"],
            "clip": self.engine.generate_image_embedding(best_image)["clip"]
        }

        return {
            "vectors": vectors,
            "search_path": "EXTERNAL",
            "strategy": "visual_rag_vlm",
            "ai_analysis": {
                "summary": summary,
                "reference_image": final_data_uri,
                "candidates": candidates_data
            },
            "description": summary,
            "ref_image": final_data_uri
        }

    async def analyze_specific_image(self, image_b64: str, query: str) -> str:
        try:
            if "base64," in image_b64:
                image_b64 = image_b64.split("base64,")[1]
            return await self._analyze_image_with_vlm(image_b64, query)
        except Exception:
            return "ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

    # [í•µì‹¬ ìˆ˜ì •] VLM ë¶„ì„ í”„ë¡¬í”„íŠ¸ ê°•í™” (Grounding)
    async def _analyze_image_with_vlm(self, image_data: Any, query: str) -> str:
        try:
            if isinstance(image_data, Image.Image):
                img_b64 = self._image_to_base64(image_data).split(",")[1]
            else:
                img_b64 = image_data

            # [Grounding Prompt] "ë³´ì´ëŠ” ê²ƒë§Œ ë¬˜ì‚¬í•˜ë¼"ëŠ” ê°•ë ¥í•œ ì œì•½ ì¶”ê°€
            vlm_prompt = f"""
            ë‹¹ì‹ ì€ ì •ì§í•œ íŒ¨ì…˜ ì—ë””í„°ì…ë‹ˆë‹¤.
            **ì˜¤ì§ ì´ë¯¸ì§€ì— ì‹œê°ì ìœ¼ë¡œ ë³´ì´ëŠ” ê²ƒë§Œ** ì„¤ëª…í•˜ì„¸ìš”. 
            ì´ë¯¸ì§€ì— ì—†ëŠ” ë‚´ìš©(ìƒìƒ, ë°°ê²½ì§€ì‹, ì¶”ì¸¡)ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
            
            ì‚¬ìš©ì ì§ˆë¬¸: "{query}" (ì°¸ê³ ìš©ì¼ ë¿, ì‹¤ì œ ì´ë¯¸ì§€ ë‚´ìš©ì´ ìš°ì„ ì…ë‹ˆë‹¤.)
            
            [ë¶„ì„ ê°€ì´ë“œ]
            1. **íŠ¸ë Œë“œ ë¬´ë“œ**: ì´ë¯¸ì§€ì—ì„œ ëŠê»´ì§€ëŠ” ì‹¤ì œ ë¶„ìœ„ê¸°ë§Œ í•œ ì¤„ë¡œ ì‘ì„±.
            2. **ìŠ¤íƒ€ì¼ë§ í¬ì¸íŠ¸**: ëˆˆì— ë³´ì´ëŠ” ì˜·ì˜ ìƒ‰ìƒ, ì†Œì¬, í•ì„ êµ¬ì²´ì ìœ¼ë¡œ ë¬˜ì‚¬ (ì˜ˆ: "ê²€ì€ìƒ‰ ê°€ì£½ ìì¼“", "íŒŒë€ìƒ‰ ë°ë‹˜ íŒ¬ì¸ ").
            3. **ì¶”ì²œ ì•„ì´í…œ**: ì´ ì‚¬ì§„ ì† ì¸ë¬¼ì´ ì°©ìš©í•œ ì•„ì´í…œê³¼ ìœ ì‚¬í•œ ì œí’ˆ ì¶”ì²œ.
            
            ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
            """
            return self.engine.generate_with_image(vlm_prompt, img_b64)
        except Exception:
            return "ë¶„ì„ ë¶ˆê°€"

    async def process_internal_search(self, query: str) -> Dict[str, Any]:
        vectors = self.engine.generate_dual_embedding(query)
        return {
            "vectors": vectors,
            "search_path": "INTERNAL",
            "strategy": "internal_text",
            "ai_analysis": None,
            "description": f"'{query}' ë‚´ë¶€ ê²€ìƒ‰ ê²°ê³¼",
            "ref_image": None
        }

    async def determine_search_path(self, query: str) -> str:
        external_triggers = ["ìŠ¤íƒ€ì¼", "ì½”ë””", "íŒ¨ì…˜", "ë£©", "ìœ í–‰", "ì—°ì˜ˆì¸", "ê³µí•­", "ì…ì€", "ì¶”ì²œ"]
        if any(t in query for t in external_triggers): return 'EXTERNAL'
        return 'INTERNAL'

rag_orchestrator = AIOrchestrator()