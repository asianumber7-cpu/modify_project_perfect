import logging
from typing import List, Dict, Any, Optional, Tuple
from PIL import Image
import numpy as np
import torch
import torch.nn as nn

logger = logging.getLogger(__name__)

class YOLOFashionDetector:
    """
    YOLO ê¸°ë°˜ íŒ¨ì…˜ ì•„ì´í…œ ê°ì§€ê¸°
    - YOLOv8ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ëŒ/ì˜ë¥˜ ì˜ì—­ ê°ì§€
    - ìƒì˜/í•˜ì˜ ì˜ì—­ ë¶„ë¦¬ ì§€ì›
    """
    
    def __init__(self):
        self.model = None
        self.pose_model = None
        self.initialized = False
        
        # COCO í´ë˜ìŠ¤ ID (person = 0)
        self.PERSON_CLASS_ID = 0
        
        # ìƒì˜/í•˜ì˜ ë¹„ìœ¨ (ì „ì²´ ì‚¬ëŒ bbox ê¸°ì¤€)
        self.UPPER_RATIO = 0.55  # ìƒìœ„ 55%ê°€ ìƒì˜
        self.LOWER_RATIO = 0.45  # í•˜ìœ„ 45%ê°€ í•˜ì˜
        
    def initialize(self):
        """YOLO ëª¨ë¸ ë¡œë“œ"""
        if self.initialized: return True
        try:
            from ultralytics import YOLO
            
            # [ë³´ì•ˆ íŒ¨ì¹˜] PyTorch Safe Globals ë“±ë¡
            try:
                from ultralytics.nn.tasks import DetectionModel
                safe_classes = [
                    DetectionModel,
                    nn.Sequential, nn.Conv2d, nn.BatchNorm2d, nn.SiLU, 
                    nn.Upsample, nn.MaxPool2d, nn.ModuleList,
                ]
                torch.serialization.add_safe_globals(safe_classes)
            except: pass

            # [ë³´ì•ˆ íŒ¨ì¹˜] weights_only=False ê°•ì œ ì ìš© (ë¡œë”© ì‹œì—ë§Œ)
            _original_load = torch.load
            def _unsafe_load(*args, **kwargs):
                if 'weights_only' not in kwargs: kwargs['weights_only'] = False
                return _original_load(*args, **kwargs)
            torch.load = _unsafe_load

            self.model = YOLO('yolov8n.pt')
            try:
                self.pose_model = YOLO('yolov8n-pose.pt')
                logger.info("âœ… YOLO Pose model loaded")
            except: self.pose_model = None
            
            # ë³µêµ¬
            torch.load = _original_load
            
            self.initialized = True
            logger.info("âœ… YOLO Fashion Detector initialized")
            return True
            
        except ImportError:
            logger.error("âŒ ultralytics not installed.")
            return False
        except Exception as e:
            logger.error(f"âŒ YOLO initialization failed: {e}")
            return False
    
    def detect_person(self, image: Image.Image) -> List[Dict[str, Any]]:
        """
        ì´ë¯¸ì§€ì—ì„œ ì‚¬ëŒ ê°ì§€
        """
        if not self.initialized:
            if not self.initialize(): return []
        
        try:
            # ğŸš¨ [FIX] 4ì±„ë„(RGBA) ì´ë¯¸ì§€ê°€ ë“¤ì–´ì˜¤ë©´ 3ì±„ë„(RGB)ë¡œ ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')

            # PIL -> numpy
            img_array = np.array(image)
            
            # YOLO ì¶”ë¡ 
            results = self.model(img_array, classes=[self.PERSON_CLASS_ID], verbose=False)
            
            persons = []
            for result in results:
                if result.boxes is None: continue
                for box in result.boxes:
                    x1, y1, x2, y2 = box.xyxy[0].tolist()
                    conf = float(box.conf[0])
                    area = (x2 - x1) * (y2 - y1)
                    
                    persons.append({
                        "bbox": (int(x1), int(y1), int(x2), int(y2)),
                        "confidence": conf,
                        "area": area
                    })
            
            persons.sort(key=lambda x: x["area"], reverse=True)
            return persons
            
        except Exception as e:
            logger.error(f"âŒ Person detection failed: {e}")
            return []
    
    def get_keypoints(self, image: Image.Image) -> Optional[Dict[str, Tuple[int, int]]]:
        if self.pose_model is None: return None
        try:
            # ğŸš¨ [FIX] í¬ì¦ˆ ì¶”ì • ì‹œì—ë„ RGB ë³€í™˜ í™•ì¸
            if image.mode != 'RGB':
                image = image.convert('RGB')
                
            img_array = np.array(image)
            results = self.pose_model(img_array, verbose=False)
            
            KEYPOINT_NAMES = {5: "left_shoulder", 6: "right_shoulder", 11: "left_hip", 12: "right_hip"}
            for result in results:
                if result.keypoints is None: continue
                keypoints = result.keypoints.xy[0].tolist()
                kp_dict = {}
                for idx, name in KEYPOINT_NAMES.items():
                    if idx < len(keypoints):
                        x, y = keypoints[idx]
                        if x > 0 and y > 0: kp_dict[name] = (int(x), int(y))
                if kp_dict: return kp_dict
            return None
        except: return None
    
    def _crop_from_bbox(self, image: Image.Image, bbox: Tuple[int,int,int,int], target: str) -> Image.Image:
        x1, y1, x2, y2 = bbox
        w, h = image.size
        
        # Padding
        px = int((x2 - x1) * 0.1)
        py = int((y2 - y1) * 0.05)
        
        x1 = max(0, x1 - px)
        y1 = max(0, y1 - py)
        x2 = min(w, x2 + px)
        y2 = min(h, y2 + py)
        
        crop_box = (x1, y1, x2, y2)
        if target == "upper":
             crop_box = (x1, y1, x2, int(y1 + (y2-y1) * self.UPPER_RATIO))
        elif target == "lower":
             crop_box = (x1, int(y1 + (y2-y1) * (1 - self.LOWER_RATIO)), x2, y2)
             
        return image.crop(crop_box)

    def crop_fashion_regions(self, image: Image.Image, target: str = "full") -> Optional[Image.Image]:
        persons = self.detect_person(image)
        if not persons: return image
        return self._crop_from_bbox(image, persons[0]["bbox"], target)
    
    def extract_fashion_features(self, image: Image.Image) -> Dict[str, Optional[Image.Image]]:
        result = {"full": None, "upper": None, "lower": None}
        
        persons = self.detect_person(image)
        if not persons:
            result["full"] = image 
            return result
            
        main_bbox = persons[0]["bbox"]
        
        # ì›ë³¸ ì´ë¯¸ì§€ê°€ RGBAë¼ë©´ ì—¬ê¸°ì„œë„ ë³€í™˜ëœ ë²„ì „ì„ ì‚¬ìš©í•˜ëŠ” ê²Œ ì•ˆì „í•˜ì§€ë§Œ,
        # cropì€ ëª¨ë“œ ìƒê´€ì—†ì´ ë™ì‘í•˜ë¯€ë¡œ ê´œì°®ìŠµë‹ˆë‹¤.
        # ë‹¤ë§Œ detect_person ë‚´ë¶€ì—ì„œ ë³€í™˜ëœ ì´ë¯¸ì§€ë¥¼ ë¦¬í„´í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, 
        # ì›ë³¸ imageë¥¼ ê·¸ëŒ€ë¡œ ì”ë‹ˆë‹¤.
        
        result["full"] = self._crop_from_bbox(image, main_bbox, "full")
        result["upper"] = self._crop_from_bbox(image, main_bbox, "upper")
        result["lower"] = self._crop_from_bbox(image, main_bbox, "lower")
        
        return result

yolo_detector = YOLOFashionDetector()