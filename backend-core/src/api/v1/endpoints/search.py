import json
import httpx
import base64
import logging
from typing import Optional, List, Dict, Any

# ğŸš¨ [ìˆ˜ì •] UploadFile ì²˜ë¦¬ë¥¼ ìœ„í•´ Form ì„í¬íŠ¸ í•„ìˆ˜
from fastapi import APIRouter, Depends, Query, HTTPException, UploadFile, File, Form
from sqlalchemy.ext.asyncio import AsyncSession

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
from src.api.deps import get_db
from src.crud.crud_product import crud_product 
from src.schemas.product import SearchQuery, ProductResponse 
from src.models.product import Product 

logger = logging.getLogger(__name__)
router = APIRouter()

# AI Service API URL (Docker ë‚´ë¶€ í†µì‹ ìš©)
AI_SERVICE_API_URL = "http://ai-service-api:8000/api/v1" 

@router.post("/ai-search", response_model=Dict[str, Any])
async def ai_search(
    # ğŸš¨ [ìˆ˜ì •] í”„ë¡ íŠ¸ì—”ë“œ FormData í˜•ì‹ì— ë§ê²Œ Form(...) ì‚¬ìš©
    query: str = Form(..., description="ì‚¬ìš©ì ê²€ìƒ‰ ì¿¼ë¦¬"),
    image_file: Optional[UploadFile] = File(None),
    limit: int = Form(10),  # limitë„ Form ë°ì´í„°ë¡œ ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²˜ë¦¬
    db: AsyncSession = Depends(get_db),
) -> Any:
    """
    í†µí•© AI ê¸°ë°˜ ìƒí’ˆ ê²€ìƒ‰: ê²½ë¡œ ê²°ì • (INTERNAL/EXTERNAL), RAG/Vision ë¶„ì„ ë° ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    logger.info(f"Received search query: '{query}' with image: {image_file is not None}")

    # 1. ì´ë¯¸ì§€ ì²˜ë¦¬ (Base64 ë³€í™˜)
    image_b64: Optional[str] = None
    if image_file:
        try:
            content = await image_file.read()
            image_b64 = base64.b64encode(content).decode("utf-8")
        except Exception as e:
            logger.error(f"Image file read error: {e}")
            raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 2. AI Service í˜¸ì¶œ íŒŒì´í”„ë¼ì¸
    async with httpx.AsyncClient(timeout=120.0) as client:
        
        # A. ê²€ìƒ‰ ê²½ë¡œ ê²°ì • (AI Orchestrator)
        try:
            path_response = await client.post(
                f"{AI_SERVICE_API_URL}/determine-path", 
                json={"query": query}
            )
            # ìƒíƒœ ì½”ë“œê°€ 200ì´ ì•„ë‹ˆë©´ ì—ëŸ¬ ë°œìƒì‹œí‚¤ì§€ ì•Šê³  ê¸°ë³¸ê°’ ì‚¬ìš©
            if path_response.status_code == 200:
                search_path = path_response.json().get("path", 'INTERNAL')
            else:
                search_path = 'INTERNAL'
            
            logger.info(f"AI determined search path: {search_path}")

        except Exception as e:
            logger.warning(f"AI Path decision failed: {e}. Defaulting to INTERNAL.")
            search_path = 'INTERNAL'

        # B. AI ì²˜ë¦¬ ë° ë²¡í„° ìƒì„± ìš”ì²­
        # ê²½ë¡œì— ë”°ë¼ ì—”ë“œí¬ì¸íŠ¸ ì„ íƒ
        ai_endpoint = "/process-external" if search_path == 'EXTERNAL' else "/process-internal"
        
        try:
            # ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì „ì†¡
            ai_payload = {"query": query, "image_b64": image_b64}
            
            ai_data_response = await client.post(
                f"{AI_SERVICE_API_URL}{ai_endpoint}", 
                json=ai_payload
            )
            ai_data_response.raise_for_status()
            
            ai_data = ai_data_response.json()
            vector: List[float] = ai_data.get("vector", [])
            reason: str = ai_data.get("reason", "AI ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.")
            
        except Exception as e:
            logger.error(f"AI processing critical error: {e}")
            raise HTTPException(status_code=500, detail=f"AI ì„œë¹„ìŠ¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    # 3. ë²¡í„° ìœ íš¨ì„± ê²€ì‚¬
    if not vector or len(vector) != 768:
        logger.error(f"Invalid vector dimension. Expected 768, got {len(vector) if vector else 0}")
        raise HTTPException(status_code=500, detail="AI ë²¡í„° ìƒì„± ì‹¤íŒ¨ (ì°¨ì› ë¶ˆì¼ì¹˜)")

    # 4. DB Vector ê²€ìƒ‰ ì‹¤í–‰ (ì—¬ê¸°ê°€ í•µì‹¬)
    try:
        # ğŸš¨ [ìˆ˜ì •] ì´ì œ crud_productì— search_by_vectorê°€ ì¡´ì¬í•˜ë¯€ë¡œ ì—ëŸ¬ê°€ ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        results: List[Product] = await crud_product.search_by_vector(
            db, 
            query_vector=vector, 
            limit=limit
        )
    except Exception as e:
        logger.error(f"Vector search failed: {e}")
        raise HTTPException(status_code=500, detail="ë°ì´í„°ë² ì´ìŠ¤ ë²¡í„° ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    # 5. ì‘ë‹µ ë°˜í™˜
    product_responses = [ProductResponse.model_validate(p) for p in results]
    
    return {
        "status": "SUCCESS",
        "answer": reason,
        "products": product_responses,
        "search_path": search_path
    }

# --------------------------------------------------------------------------
# [ê¸°ì¡´ ì½”ë“œ ìœ ì§€] ê¸°íƒ€ ê¸°ëŠ¥ (ê°€ê²©ëŒ€ë³„, ì½”ë”” ì¶”ì²œ ë“±)
# --------------------------------------------------------------------------

@router.get("/related-price/{product_id}")
async def get_related_by_price(product_id: int, db: AsyncSession = Depends(get_db)):
    """ 3. ë¹„ìŠ·í•œ ê°€ê²©ëŒ€ì˜ ìƒí’ˆ ì¶”ì²œ (êµ¬í˜„ ì˜ˆì •) """
    return {"message": f"Feature 3: Price-based search for product {product_id} is pending implementation."}

@router.get("/ai-coordination/{product_id}")
async def get_ai_coordination(product_id: int, db: AsyncSession = Depends(get_db)):
    """ 4. AI ì½”ë”” ì¶”ì²œ (êµ¬í˜„ ì˜ˆì •) """
    return {"message": f"Feature 4: AI Coordination for product {product_id} is pending implementation."}