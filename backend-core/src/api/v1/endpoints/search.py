import logging
import base64
import asyncio
import re
from typing import Optional, List, Dict, Any
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form
from sqlalchemy.ext.asyncio import AsyncSession
import httpx
from pydantic import BaseModel, ValidationError 

from src.api import deps
from src.crud.crud_product import crud_product
from src.schemas.product import ProductResponse
from src.config.settings import settings
from src.constants import ProductCategory

logger = logging.getLogger(__name__)
router = APIRouter()

# ------------------------------------------------------------------
# DTO Definitions
# ------------------------------------------------------------------

class ImageAnalysisRequest(BaseModel):
    image_b64: str
    query: str

class ClipSearchRequest(BaseModel):
    image_b64: str
    limit: int = 12
    query: Optional[str] = None  # ì›ë³¸ ê²€ìƒ‰ì–´ (ì„±ë³„ ì¶”ì¶œìš©)
    target: str = "full"  # "full", "upper", "lower"

# ------------------------------------------------------------------
# Helper Functions
# ------------------------------------------------------------------

def detect_gender_intent(query: str) -> Optional[str]:
    """ê²€ìƒ‰ì–´ì—ì„œ ì„±ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    if not query:
        return None
    q = query.lower()
    if any(x in q for x in ["ë‚¨ì", "ë‚¨ì„±", "ë§¨", "men", "male", "boy"]):
        return "Male"
    elif any(x in q for x in ["ì—¬ì", "ì—¬ì„±", "ìš°ë¨¼", "women", "female", "girl"]):
        return "Female"
    return None

def extract_core_keyword(query: str) -> str:
    """ê²€ìƒ‰ì–´ì—ì„œ í•µì‹¬ ìƒí’ˆ í‚¤ì›Œë“œ ì¶”ì¶œ (ì„±ë³„/ìˆ˜ì‹ì–´ ì œê±°)"""
    if not query:
        return ""
        
    # ì œê±°í•  ë‹¨ì–´ë“¤
    remove_words = [
        "ë‚¨ì", "ì—¬ì", "ë‚¨ì„±", "ì—¬ì„±", "ë‚¨ì„±ìš©", "ì—¬ì„±ìš©",
        "ì¶”ì²œ", "í•´ì¤˜", "ë³´ì—¬ì¤˜", "ì°¾ì•„ì¤˜", "ì•Œë ¤ì¤˜",
        "ìŠ¤íƒ€ì¼", "íŒ¨ì…˜", "ì˜ë¥˜", "ìš©"
    ]
    # âœ… [FIX] "ì˜·"ì€ ì œê±°í•˜ì§€ ì•ŠìŒ - ê²€ìƒ‰ì–´ë¡œ ìœ ì˜ë¯¸í•¨
    
    result = query
    for word in remove_words:
        result = result.replace(word, "")
    
    # ì¡°ì‚¬ ì œê±° (ì€/ëŠ”/ì´/ê°€ ë“±)
    result = re.sub(r'(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì˜|ì—|ë¡œ)$', '', result.strip())
    
    return result.strip() if result.strip() else query

def is_celebrity_search(query: str) -> bool:
    """ì—°ì˜ˆì¸/ì¸ë¬¼ ê²€ìƒ‰ì¸ì§€ íŒë‹¨"""
    if not query:
        return False
        
    # íŒ¨ì…˜ ê´€ë ¨ í‚¤ì›Œë“œì™€ í•¨ê»˜ ì‚¬ìš©ëœ ê²½ìš°
    fashion_keywords = ["íŒ¨ì…˜", "ìŠ¤íƒ€ì¼", "ì½”ë””", "ë£©", "ê³µí•­", "ì°©ì¥", "ì˜ìƒ", "ì˜·"]
    
    # í•œê¸€ ì´ë¦„ íŒ¨í„´ (2-4ê¸€ì)
    korean_name = re.search(r'[ê°€-í£]{2,4}', query)
    
    if korean_name and any(k in query for k in fashion_keywords):
        return True
    
    return False

async def fetch_image_as_base64(url: str) -> Optional[str]:
    """ì™¸ë¶€ ì´ë¯¸ì§€ í”„ë¡ì‹œ ë‹¤ìš´ë¡œë“œ"""
    if not url:
        return None
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Referer": "https://www.google.com/"
        }
        async with httpx.AsyncClient(timeout=5.0, verify=False) as client:
            response = await client.get(url, headers=headers)
            if response.status_code == 200:
                b64_data = base64.b64encode(response.content).decode('utf-8')
                content_type = response.headers.get("content-type", "image/jpeg")
                return f"data:{content_type};base64,{b64_data}"
    except Exception as e:
        logger.warning(f"âš ï¸ Failed to proxy image ({url}): {e}")
    return None


# âœ… [NEW] Response ë§¤í•‘ í—¬í¼ í•¨ìˆ˜
def map_product_to_response(product) -> Optional[ProductResponse]:
    """Product ê°ì²´ë¥¼ ProductResponseë¡œ ë³€í™˜ (similarity í¬í•¨)"""
    try:
        p_dict = {
            "id": product.id,
            "name": product.name or "Unnamed Product",
            "description": product.description or "",
            "price": float(product.price) if product.price else 0,
            "stock_quantity": int(product.stock_quantity) if product.stock_quantity else 0,
            "category": product.category or "Etc",
            "image_url": product.image_url or "",
            "gender": product.gender or "Unisex",
            "is_active": product.is_active if product.is_active is not None else True,
            "created_at": product.created_at,
            "updated_at": product.updated_at,
            "in_stock": (product.stock_quantity or 0) > 0,
            # âœ… [FIX] similarity í•„ë“œ ì¶”ê°€
            "similarity": getattr(product, 'similarity', None)
        }
        return ProductResponse.model_validate(p_dict)
    except ValidationError as e:
        logger.warning(f"âš ï¸ Product validation error: {e}")
        return None


# ------------------------------------------------------------------
# Endpoints
# ------------------------------------------------------------------

@router.post("/search-by-clip")
async def search_by_clip_image(
    request: ClipSearchRequest,
    db: AsyncSession = Depends(deps.get_db),
):
    """
    ì´ë¯¸ì§€ ê¸°ë°˜ ìƒí’ˆ ê²€ìƒ‰ (CLIP Vector)
    - í›„ë³´ ì´ë¯¸ì§€ í´ë¦­ ì‹œ í˜¸ì¶œ
    - ì´ë¯¸ì§€ â†’ CLIP ë²¡í„° â†’ ìœ ì‚¬ ìƒí’ˆ ê²€ìƒ‰
    - target: "full"(ì „ì²´), "upper"(ìƒì˜), "lower"(í•˜ì˜)
    """
    logger.info(f"ğŸ–¼ï¸ CLIP Image Search Request (limit: {request.limit}, query: {request.query}, target: {request.target})")
    
    # 1. ì›ë³¸ ì¿¼ë¦¬ì—ì„œ ì„±ë³„ ì¶”ì¶œ
    target_gender = None
    if request.query:
        target_gender = detect_gender_intent(request.query)
        logger.info(f"ğŸ“Œ Detected gender from query: {target_gender}")

    target_categories = None
    if request.target == "upper":
        # ìƒì˜ë¼ê³  íŒë‹¨ë˜ë©´ Tops, Outerwear, Dresses ê²€ìƒ‰
        target_categories = [
            ProductCategory.TOPS.value, 
            ProductCategory.OUTERWEAR.value, 
            ProductCategory.DRESSES.value
        ]
    elif request.target == "lower":
        # í•˜ì˜ë¼ê³  íŒë‹¨ë˜ë©´ Bottoms ê²€ìƒ‰
        target_categories = [ProductCategory.BOTTOMS.value] 
    
    AI_SERVICE_API_URL = settings.AI_SERVICE_API_URL.rstrip("/")
    
    try:
        # 2. AI ì„œë¹„ìŠ¤ì—ì„œ CLIP ë²¡í„° ìƒì„± (Fashion CLIP or Standard CLIP)
        async with httpx.AsyncClient(timeout=30.0) as client:
            clip_res = await client.post(
                f"{AI_SERVICE_API_URL}/generate-fashion-clip-vector",
                json={
                    "image_b64": request.image_b64,
                    "target": request.target  # ì˜ì—­ ì§€ì •
                }
            )
            
            if clip_res.status_code != 200:
                # Fallback: ê¸°ì¡´ CLIP ì—”ë“œí¬ì¸íŠ¸
                logger.warning("âš ï¸ Fashion CLIP endpoint failed, falling back to standard CLIP")
                clip_res = await client.post(
                    f"{AI_SERVICE_API_URL}/generate-clip-vector",
                    json={"image_b64": request.image_b64}
                )
            
            if clip_res.status_code != 200:
                raise HTTPException(status_code=500, detail="CLIP ë²¡í„° ìƒì„± ì‹¤íŒ¨")
            
            clip_data = clip_res.json()
            clip_vector = clip_data.get("vector", [])
            
            if not clip_vector or len(clip_vector) != 512:
                raise HTTPException(status_code=500, detail="ìœ íš¨í•˜ì§€ ì•Šì€ CLIP ë²¡í„°")
        
        logger.info(f"âœ… CLIP vector generated: {len(clip_vector)} dims (target: {request.target})")
        
        # 3. CLIP ë²¡í„°ë¡œ ìƒí’ˆ ê²€ìƒ‰ (ì„±ë³„ í•„í„° ì ìš©)
        results = await crud_product.search_by_clip_vector(
            db,
            clip_vector=clip_vector,
            limit=request.limit,
            filter_gender=target_gender,
            target=request.target,
            include_category=target_categories
        )
        
        logger.info(f"âœ… CLIP search found {len(results)} products (gender filter: {target_gender})")
        
        # 4. Response êµ¬ì„± (with similarity)
        product_responses = []
        for p in results:
            response = map_product_to_response(p)
            if response:
                product_responses.append(response)
        
        return {
            "status": "SUCCESS",
            "search_type": "CLIP_IMAGE_SIMILARITY",
            "products": product_responses
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ CLIP search failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/analyze-image")
async def analyze_image_proxy(request: ImageAnalysisRequest):
    """ê°œë³„ ì´ë¯¸ì§€ ë¶„ì„ í”„ë¡ì‹œ (í›„ë³´ ì´ë¯¸ì§€ ìƒì„¸ ë¶„ì„)"""
    AI_SERVICE_API_URL = settings.AI_SERVICE_API_URL.rstrip("/")
    try:
        async with httpx.AsyncClient(timeout=60.0) as client:
            target_url = f"{AI_SERVICE_API_URL}/analyze-image-detail"
            # URL ê²½ë¡œ ë³´ì •
            if "/api/v1" not in AI_SERVICE_API_URL and "/api/v1" not in target_url:
                 # AI Service êµ¬ì¡°ì— ë”°ë¼ ìœ ë™ì ì¼ ìˆ˜ ìˆìŒ, ì—¬ê¸°ì„  ì•ˆì „í•˜ê²Œ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
                 pass 

            logger.info(f"ğŸ“¤ Calling AI Service: {target_url}")

            response = await client.post(
                target_url,
                json={"image_b64": request.image_b64, "query": request.query}
            )
            response.raise_for_status()
            return response.json()
    except httpx.HTTPStatusError as e:
        logger.error(f"âŒ AI Service HTTP Error: {e.response.status_code} - {e.response.text}")
        raise HTTPException(status_code=502, detail=f"AI Service Error: {e.response.status_code}")
    except Exception as e:
        logger.error(f"âŒ Analysis Proxy Failed: {e}")
        raise HTTPException(status_code=500, detail=f"AI Service Error: {str(e)}")


@router.post("/ai-search", response_model=Dict[str, Any])
async def ai_search(
    query: str = Form(..., description="ì‚¬ìš©ì ê²€ìƒ‰ ì¿¼ë¦¬"),
    image_file: Optional[UploadFile] = File(None),
    limit: int = Form(12),
    db: AsyncSession = Depends(deps.get_db),
) -> Any:
    """
    [Upgraded v2] ìŠ¤ë§ˆíŠ¸ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
    1. í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ì…ë ¥ -> AI ì„œë¹„ìŠ¤ë¡œ ê²½ë¡œ(Internal/External) íŒë‹¨
    2. EXTERNAL: ì™¸ë¶€ ì´ë¯¸ì§€/íŠ¸ë Œë“œ ë¶„ì„ -> CLIP ë²¡í„° ìƒì„± -> ì‹œê°ì  ìœ ì‚¬ë„ ìƒí’ˆ ê²€ìƒ‰
    3. INTERNAL: í•µì‹¬ í‚¤ì›Œë“œ + BERT/CLIP ë²¡í„° -> í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
    """
    logger.info(f"ğŸ” AI Search Request: '{query}' (Image: {image_file is not None})")

    # 1. ì˜ë„ ë° ì •ë³´ ì¶”ì¶œ
    target_gender = detect_gender_intent(query)
    core_keyword = extract_core_keyword(query)
    is_celeb_search = is_celebrity_search(query)
    
    logger.info(f"ğŸ“Œ Gender: {target_gender}, Core Keyword: '{core_keyword}', Celebrity: {is_celeb_search}")

    # 2. ì—…ë¡œë“œ ì´ë¯¸ì§€ ì²˜ë¦¬
    image_b64: Optional[str] = None
    if image_file:
        try:
            content = await image_file.read()
            image_b64 = base64.b64encode(content).decode("utf-8")
        except Exception:
            raise HTTPException(status_code=400, detail="Invalid image file")

    # 3. AI Service í˜¸ì¶œ (ê²½ë¡œ íŒë‹¨ ë° ë²¡í„° ìƒì„±)
    AI_SERVICE_API_URL = settings.AI_SERVICE_API_URL.rstrip("/")
    
    search_strategy = "SMART_HYBRID"
    search_path = "INTERNAL"
    ai_summary = "ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤."
    ref_image_url = None
    candidates = []
    
    bert_vec: Optional[List[float]] = None
    clip_vec: Optional[List[float]] = None
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            async with httpx.AsyncClient(timeout=120.0) as client:
                # 3-1. ê²½ë¡œ ê²°ì • API í˜¸ì¶œ
                path_res = await client.post(
                    f"{AI_SERVICE_API_URL}/determine-path",
                    json={"query": query}
                )
                
                search_path = "INTERNAL"
                if path_res.status_code == 200:
                    search_path = path_res.json().get("path", "INTERNAL")
                
                logger.info(f"ğŸ›¤ï¸ Search Path Decision: {search_path}")
                
                # 3-2. ê²½ë¡œì— ë”°ë¥¸ ìƒì„¸ ì²˜ë¦¬ í˜¸ì¶œ
                endpoint = "/process-external" if search_path == 'EXTERNAL' else "/process-internal"
                
                # URL ê²°í•© ì‹œ ì¤‘ë³µ ìŠ¬ë˜ì‹œ ë°©ì§€
                target_ai_url = f"{AI_SERVICE_API_URL}{endpoint}"
                
                payload = {"query": query, "image_b64": image_b64}
                ai_res = await client.post(target_ai_url, json=payload)
                ai_res.raise_for_status()
                
                data = ai_res.json()
                
                # ë²¡í„° ì¶”ì¶œ
                if "vectors" in data:
                    bert_vec = data["vectors"].get("bert")
                    clip_vec = data["vectors"].get("clip")
                    logger.info(f"ğŸ“Š Vectors received - BERT: {len(bert_vec) if bert_vec else 0}dim, CLIP: {len(clip_vec) if clip_vec else 0}dim")
                elif "vector" in data:
                    bert_vec = data["vector"]
                
                # AI ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
                if "ai_analysis" in data and data["ai_analysis"]:
                    analysis = data["ai_analysis"]
                    ai_summary = analysis.get("summary") or ai_summary
                    ref_image_url = analysis.get("reference_image")
                    candidates = analysis.get("candidates", [])
                else:
                    ai_summary = data.get("description") or data.get("reason") or ai_summary
                    ref_image_url = data.get("ref_image")
                
                search_strategy = data.get("strategy", search_path).upper()
                
                # ì™¸ë¶€ ì´ë¯¸ì§€ URLì´ë©´ í”„ë¡ì‹œ ì²˜ë¦¬ (CORS ë°©ì§€)
                if ref_image_url and ref_image_url.startswith("http"):
                    logger.info(f"ğŸ”„ Proxying reference image...")
                    proxy_image = await fetch_image_as_base64(ref_image_url)
                    if proxy_image:
                        ref_image_url = proxy_image
                
                break  # ì„±ê³µ ì‹œ ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ

        except Exception as e:
            logger.warning(f"âš ï¸ AI Service Retry ({attempt+1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                search_strategy = "KEYWORD_FALLBACK"
                logger.error(f"âŒ AI Service failed after {max_retries} retries")
            await asyncio.sleep(1)

    # 4. ğŸŒŸ ê²€ìƒ‰ ì‹¤í–‰ - DB ì¡°íšŒ
    results = []
    gender_filtered = True  # ì„±ë³„ í•„í„° ì ìš© ì—¬ë¶€ ì¶”ì 
    
    try:
        # Case A: EXTERNAL ê²½ë¡œì´ë©´ì„œ CLIP ë²¡í„°ê°€ ìˆëŠ” ê²½ìš° (í•µì‹¬ ê¸°ëŠ¥!)
        if search_path == "EXTERNAL" and clip_vec and len(clip_vec) == 512:
            logger.info(f"ğŸ–¼ï¸ Using CLIP image vector search (512-dim)")
            
            # CLIP ì´ë¯¸ì§€ ë²¡í„°ë¡œ ì‹œê°ì  ìœ ì‚¬ë„ ê²€ìƒ‰
            results = await crud_product.search_by_clip_vector(
                db,
                clip_vector=clip_vec,
                limit=limit,
                filter_gender=target_gender
            )
            
            if results:
                search_strategy = "CLIP_VISUAL_SEARCH"
                logger.info(f"âœ… CLIP search found {len(results)} products")
            else:
                # CLIP ê²€ìƒ‰ ê²°ê³¼ ì—†ìœ¼ë©´ BERTë¡œ Fallback
                logger.info(f"âš ï¸ CLIP search empty, falling back to BERT")
                if bert_vec and len(bert_vec) == 768:
                    results = await crud_product.search_hybrid(
                        db,
                        bert_vector=bert_vec,
                        limit=limit,
                        filter_gender=target_gender
                    )
                    search_strategy = "BERT_FALLBACK"
        
        # Case B: INTERNAL ê²½ë¡œ ë˜ëŠ” ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ -> ìŠ¤ë§ˆíŠ¸ í•˜ì´ë¸Œë¦¬ë“œ (í‚¤ì›Œë“œ + ë²¡í„°)
        if not results:
            results = await crud_product.search_smart_hybrid(
                db,
                query=core_keyword,  # í•µì‹¬ í‚¤ì›Œë“œ ìš°ì„ 
                bert_vector=bert_vec,
                clip_vector=clip_vec,
                limit=limit,
                filter_gender=target_gender
            )
            
            # âœ… [FIX] ê²°ê³¼ ì—†ìœ¼ë©´ ì„±ë³„ í•„í„°ë¥¼ ì™„í™”í•˜ë˜ ì „ì²´ ì¿¼ë¦¬ë¡œ ì¬ì‹œë„
            # í•˜ì§€ë§Œ í•„í„° ì™„í™” ì‚¬ì‹¤ì„ ì¶”ì 
            if not results:
                logger.info(f"âš ï¸ No results with gender filter '{target_gender}', trying relaxed search")
                results = await crud_product.search_smart_hybrid(
                    db,
                    query=query,
                    bert_vector=bert_vec,
                    clip_vector=clip_vec,
                    limit=limit,
                    filter_gender=None  # ì„±ë³„ í•„í„° í•´ì œ
                )
                if results:
                    search_strategy = "RELAXED_SEARCH"
                    gender_filtered = False
                    logger.info(f"âš ï¸ Relaxed search found {len(results)} products (gender filter removed)")
        
        # Case C: ìµœí›„ì˜ ìˆ˜ë‹¨ (ìµœì‹  ìƒí’ˆ)
        if not results:
            results = await crud_product.get_multi(db, limit=limit)
            search_strategy = "FALLBACK_LATEST"
            gender_filtered = False

    except Exception as e:
        logger.error(f"âŒ DB Search Error: {e}")
        # DB ì—ëŸ¬ê°€ ë‚˜ë„ ì•±ì´ ì£½ì§€ ì•Šë„ë¡ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ í˜¹ì€ ì—ëŸ¬ ì²˜ë¦¬
        raise HTTPException(status_code=500, detail="Database Search Failed")

    # 5. âœ… [FIX] Response ë§¤í•‘ (similarity í¬í•¨)
    product_responses = []
    for p in results:
        response = map_product_to_response(p)
        if response:
            product_responses.append(response)

    logger.info(f"âœ… Search Complete: {len(product_responses)} products found (Strategy: {search_strategy})")

    return {
        "status": "SUCCESS",
        "search_path": search_strategy,
        "gender_filter_applied": gender_filtered,  # âœ… [NEW] ì„±ë³„ í•„í„° ì ìš© ì—¬ë¶€
        "detected_gender": target_gender,  # âœ… [NEW] ê°ì§€ëœ ì„±ë³„
        "ai_analysis": {
            "summary": ai_summary,
            "reference_image": ref_image_url,
            "candidates": candidates
        },
        "products": product_responses
    }