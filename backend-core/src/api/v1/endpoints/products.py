import logging
import csv
import io
import json
import shutil # [í•„ìˆ˜] íŒŒì¼ ì €ì¥ì„ ìœ„í•´ í•„ìš”
import os     # [í•„ìˆ˜] ê²½ë¡œ ì„¤ì •ì„ ìœ„í•´ í•„ìš”
import uuid   # [í•„ìˆ˜] íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ í•„ìš”
from typing import Any, Dict, List, Optional

from fastapi import APIRouter, Depends, HTTPException, Query, File, UploadFile, Form
from sqlalchemy.ext.asyncio import AsyncSession
from pydantic import BaseModel
import httpx 

from src.api.deps import get_db, get_current_user
from src.models.product import Product
from src.schemas.product import ProductResponse, ProductCreate
from src.crud.crud_product import crud_product 
from src.schemas.user import UserResponse as User

logger = logging.getLogger(__name__)
router = APIRouter()

AI_SERVICE_API_URL = "http://ai-service-api:8000/api/v1" 

# --- Pydantic ëª¨ë¸ ì •ì˜ ---
class LLMQueryBody(BaseModel):
    question: str
    
class CoordinationResponse(BaseModel): 
    answer: str
    products: List[ProductResponse]

# ğŸš¨ Helper: ë¬¸ìì—´ ë‚´ Null Byte ì œê±°
def sanitize_string(value: Any) -> Any:
    if isinstance(value, str):
        return value.replace("\x00", "").strip()
    return value

# =========================================================
# 1ï¸âƒ£ [Mode 1] ì´ë¯¸ì§€ ìë™ ë¶„ì„ ì—…ë¡œë“œ (AI ë¶„ì„ + ë¡œì»¬ ì €ì¥)
# =========================================================
@router.post("/upload/image-auto", response_model=ProductResponse)
async def upload_product_image_auto(
    file: UploadFile = File(...),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """
    ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´:
    1. ì„œë²„ ë‚´ë¶€ static í´ë”ì— ì´ë¯¸ì§€ë¥¼ ì €ì¥í•˜ê³ ,
    2. AIê°€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ìƒí’ˆ ì •ë³´ë¥¼ ìƒì„±í•œ ë’¤,
    3. ì €ì¥ëœ ì´ë¯¸ì§€ URLê³¼ í•¨ê»˜ DBì— ë“±ë¡í•©ë‹ˆë‹¤.
    """
    if not current_user.is_superuser:
        raise HTTPException(status_code=403, detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")

    # -------------------------------------------------------
    # [Step A] AI ì„œë¹„ìŠ¤ë¡œ ì´ë¯¸ì§€ ì „ì†¡ (ë¶„ì„ ìš”ì²­)
    # -------------------------------------------------------
    ai_analyzed_data = {}
    
    async with httpx.AsyncClient(timeout=40.0) as client:
        try:
            await file.seek(0) # íŒŒì¼ í¬ì¸í„° ì´ˆê¸°í™”
            files = {"file": (file.filename, file.file, file.content_type)}
            
            response = await client.post(
                f"{AI_SERVICE_API_URL}/analyze-image",
                files=files
            )
            
            if response.status_code != 200:
                logger.error(f"AI Service Error: {response.text}")
                raise HTTPException(status_code=502, detail="AI ì„œë¹„ìŠ¤ ë¶„ì„ ì‹¤íŒ¨")
                
            ai_analyzed_data = response.json()
            
        except httpx.RequestError as e:
            logger.error(f"AI Connection Error: {e}")
            raise HTTPException(status_code=503, detail="AI ì„œë¹„ìŠ¤ ì—°ê²° ë¶ˆê°€")

    # -------------------------------------------------------
    # [Step B] ì´ë¯¸ì§€ë¥¼ ì„œë²„ ë¡œì»¬ í´ë”ì— ì‹¤ì œë¡œ ì €ì¥
    # -------------------------------------------------------
    try:
        # 1. ì €ì¥í•  í´ë” ê²½ë¡œ (static/images)
        UPLOAD_DIR = "static/images"
        os.makedirs(UPLOAD_DIR, exist_ok=True)
        
        # 2. ìœ ë‹ˆí¬í•œ íŒŒì¼ëª… ìƒì„± (ì¤‘ë³µ ë°©ì§€)
        file_ext = os.path.splitext(file.filename)[1]
        unique_filename = f"{uuid.uuid4()}{file_ext}"
        file_path = os.path.join(UPLOAD_DIR, unique_filename)
        
        # 3. íŒŒì¼ ì €ì¥ 
        # (ì£¼ì˜: AI ì „ì†¡ ë•Œ íŒŒì¼ì„ ì½ì—ˆìœ¼ë¯€ë¡œ í¬ì¸í„°ë¥¼ ë‹¤ì‹œ 0ìœ¼ë¡œ ëŒë ¤ì•¼ í•¨)
        await file.seek(0) 
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
            
        # 4. DBì— ì €ì¥ë  ì ‘ì† ê°€ëŠ¥í•œ URL ìƒì„±
        # (ê°œë°œ í™˜ê²½: localhost, ì‹¤ì œ ë°°í¬ ì‹œ ë„ë©”ì¸ìœ¼ë¡œ ë³€ê²½)
        final_image_url = f"http://localhost:8000/static/images/{unique_filename}"
        
    except Exception as e:
        logger.error(f"File Save Error: {e}")
        raise HTTPException(status_code=500, detail="ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")

    # -------------------------------------------------------
    # [Step C] DB ì €ì¥
    # -------------------------------------------------------
    product_in_data = {
        "name": sanitize_string(ai_analyzed_data.get("name", f"Auto Product {file.filename}")),
        "category": sanitize_string(ai_analyzed_data.get("category", "Uncategorized")),
        "description": sanitize_string(ai_analyzed_data.get("description", "")),
        "price": ai_analyzed_data.get("price", 0),
        "stock_quantity": 100,
        "image_url": final_image_url, # ğŸ‘ˆ ì‹¤ì œ ì €ì¥ëœ URL ì‚¬ìš©
        "embedding": ai_analyzed_data.get("vector", []),
        "is_active": True
    }

    try:
        new_product = await crud_product.create(db, obj_in=product_in_data)
        return new_product
    except Exception as e:
        logger.error(f"DB Insert Error: {e}")
        raise HTTPException(status_code=500, detail="ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨")


# =========================================================
# 2ï¸âƒ£ [Mode 2] CSV ëŒ€ëŸ‰ ì—…ë¡œë“œ
# =========================================================
@router.post("/upload/csv")
async def upload_products_csv(
    file: UploadFile = File(...),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """
    [CSV ì „ìš©] CSV íŒŒì¼ì„ ì½ì–´ ëŒ€ëŸ‰ìœ¼ë¡œ ìƒí’ˆì„ ë“±ë¡í•©ë‹ˆë‹¤. (ì¸ì½”ë”© ìë™ ê°ì§€)
    """
    if not current_user.is_superuser:
        raise HTTPException(status_code=403, detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")

    # 1. íŒŒì¼ ì½ê¸° ë° ì¸ì½”ë”© ì²˜ë¦¬
    content = await file.read()
    try:
        decoded_content = content.decode("utf-8")
    except UnicodeDecodeError:
        try:
            decoded_content = content.decode("cp949")
        except UnicodeDecodeError:
            decoded_content = content.decode("euc-kr", errors="ignore")

    csv_reader = csv.DictReader(io.StringIO(decoded_content))
    
    results = {"success": 0, "failed": 0, "errors": []}

    for row in csv_reader:
        try:
            name = row.get("name") or row.get("ìƒí’ˆëª…")
            if not name: continue 

            category = row.get("category") or row.get("ì¹´í…Œê³ ë¦¬") or "Uncategorized"
            description = row.get("description") or row.get("ì„¤ëª…") or ""
            
            price_raw = row.get("price") or row.get("ê°€ê²©") or "0"
            price = int(str(price_raw).replace(",", "").strip())

            stock_raw = row.get("stock_quantity") or row.get("ì¬ê³ ") or "100"
            stock = int(str(stock_raw).replace(",", "").strip())
            
            image_url = row.get("image_url") or row.get("ì´ë¯¸ì§€") or "https://placehold.co/400x500?text=No+Image"

            # ì„ë² ë”© ìƒì„± (AI ì„œë¹„ìŠ¤ í˜¸ì¶œ)
            vector = []
            text_for_vector = f"{name} {category} {description}"
            
            async with httpx.AsyncClient(timeout=5.0) as client:
                try:
                    res = await client.post(
                        f"{AI_SERVICE_API_URL}/embed-text", 
                        json={"text": text_for_vector}
                    )
                    if res.status_code == 200:
                        vector = res.json().get("vector", [])
                except Exception:
                    pass 

            # DB ì €ì¥
            product_in = {
                "name": sanitize_string(name),
                "category": sanitize_string(category),
                "description": sanitize_string(description),
                "price": price,
                "stock_quantity": stock,
                "image_url": image_url,
                "embedding": vector,
                "is_active": True
            }
            
            await crud_product.create(db, obj_in=product_in)
            results["success"] += 1

        except Exception as e:
            results["failed"] += 1
            results["errors"].append(f"{name}: {str(e)}")

    return results


# =========================================================
# 3ï¸âƒ£ ê¸°ì¡´ ì¼ë°˜ API (CRUD, Recommendation, LLM Query)
# =========================================================

@router.post("/", response_model=ProductResponse)
async def create_product(
    *,
    db: AsyncSession = Depends(get_db),
    product_in: ProductCreate,
    current_user: User = Depends(get_current_user),
) -> Any:
    """ë‹¨ì¼ ìƒí’ˆ ì§ì ‘ ìƒì„± (ê´€ë¦¬ì)"""
    if not current_user.is_superuser:
        raise HTTPException(status_code=403, detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")

    product_data = product_in.model_dump()
    for key, value in product_data.items():
        product_data[key] = sanitize_string(value)

    embedding_vector = []
    text_to_embed = f"ìƒí’ˆëª…: {product_data['name']} | ì¹´í…Œê³ ë¦¬: {product_data.get('category', '')} | ì„¤ëª…: {product_data.get('description', '')}"

    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.post(
                f"{AI_SERVICE_API_URL}/embed-text",
                json={"text": text_to_embed}
            )
            if response.status_code == 200:
                embedding_vector = response.json().get("vector", [])
    except Exception as e:
        logger.error(f"âŒ Failed to generate embedding: {e}")

    if embedding_vector:
        product_data["embedding"] = embedding_vector

    product = await crud_product.create(db, obj_in=product_data)
    return product

@router.get("/{product_id}", response_model=ProductResponse)
async def read_product(
    product_id: int,
    db: AsyncSession = Depends(get_db),
) -> Any:
    product = await crud_product.get(db, product_id=product_id)
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")
    return product

@router.post("/{product_id}/llm-query", response_model=Dict[str, str])
async def llm_query_product(
    product_id: int,
    query_body: LLMQueryBody,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user),
) -> Dict[str, str]:
    product = await crud_product.get(db, product_id=product_id)
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")

    context = (
        f"ìƒí’ˆëª…: {product.name}, ì¹´í…Œê³ ë¦¬: {product.category}, ê°€ê²©: {product.price}ì›, "
        f"ê¸°ì¡´ ì„¤ëª…: {product.description}"
    )
    
    prompt = (
        f"ì‚¬ìš©ì ì§ˆë¬¸: {query_body.question}\n"
        f"ë‹¤ìŒ ìƒí’ˆ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ê°€ì²˜ëŸ¼ ë‹µë³€í•˜ì„¸ìš”: {context}"
    )

    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            ai_response = await client.post(
                f"{AI_SERVICE_API_URL}/llm-generate-response", 
                json={"prompt": prompt}
            )
            ai_response.raise_for_status()
            ai_data = ai_response.json()
            return {"answer": ai_data.get("answer", "ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")}
        except Exception as e:
            logger.error(f"LLM Query failed: {e}")
            raise HTTPException(status_code=503, detail="AI ì„œë¹„ìŠ¤ í†µì‹  ì˜¤ë¥˜")

@router.get("/ai-coordination/{product_id}", response_model=CoordinationResponse)
async def get_ai_coordination_products(
    product_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user),
) -> CoordinationResponse:
    product = await crud_product.get(db, product_id=product_id)
    if not product or not product.embedding:
        raise HTTPException(status_code=404, detail="ìƒí’ˆì„ ì°¾ê±°ë‚˜ ë²¡í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    coordination_prompt = (
        f"ìƒí’ˆëª… '{product.name}', ì¹´í…Œê³ ë¦¬ '{product.category}'ì˜ ì½”ë””ì— ì í•©í•œ "
        f"ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬(ì˜ˆ: ìƒì˜ë©´ í•˜ì˜, ì•„ìš°í„°ë©´ ì´ë„ˆ)ì˜ ìƒí’ˆì„ ì°¾ê¸° ìœ„í•œ "
        f"ìµœì ì˜ ê²€ìƒ‰ í‚¤ì›Œë“œ 5ê°œ(ìŠ¤íƒ€ì¼, ì¹´í…Œê³ ë¦¬ í¬í•¨)ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”."
    )

    async with httpx.AsyncClient(timeout=30.0) as client:
        try:
            llm_res = await client.post(
                f"{AI_SERVICE_API_URL}/llm-generate-response", 
                json={"prompt": coordination_prompt}
            )
            llm_res.raise_for_status()
            coordination_keywords = llm_res.json().get("answer", "ìºì£¼ì–¼, ê¸°ë³¸, ì¶”ì²œ").split(',')
            coordination_keywords = [k.strip() for k in coordination_keywords]
        except Exception:
            coordination_keywords = ["ê¸°ë³¸", "ì¶”ì²œ", "ìŠ¤íƒ€ì¼"]

    embedding_text = f"{product.name} ì½”ë””, {', '.join(coordination_keywords)}"
    coordination_vector: List[float]
    try:
        vector_res = await client.post(
            f"{AI_SERVICE_API_URL}/embed-text", 
            json={"text": embedding_text}
        )
        vector_res.raise_for_status()
        coordination_vector = vector_res.json().get("vector", [])
    except Exception as e:
        logger.error(f"Embedding API failed: {e}")
        raise HTTPException(status_code=503, detail="AI ì½”ë”” ë²¡í„° ìƒì„± ì‹¤íŒ¨")

    coordination_products = await crud_product.search_by_vector(
        db, 
        query_vector=coordination_vector, 
        limit=5, 
        exclude_category=[product.category]
    )

    coordination_reason = (
        f"ì´ '{product.name}'ì™€ í•¨ê»˜ íŠ¸ë Œë””í•œ ë£©ì„ ì™„ì„±í•  ìˆ˜ ìˆëŠ” "
        f"ìµœì ì˜ ì½”ë”” ìƒí’ˆì„ ì¶”ì²œí•´ ë“œë¦½ë‹ˆë‹¤. ì»¨ì…‰: {', '.join(coordination_keywords[:3])}"
    )

    return CoordinationResponse(
        answer=coordination_reason,
        products=[ProductResponse.model_validate(p) for p in coordination_products]
    )

@router.get("/related-price/{product_id}", response_model=CoordinationResponse)
async def get_related_by_price(
    product_id: int, 
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user),
) -> CoordinationResponse:
    product = await crud_product.get(db, product_id=product_id)
    if not product or not product.embedding:
        raise HTTPException(status_code=404, detail="ìƒí’ˆì„ ì°¾ê±°ë‚˜ ë²¡í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    price_range = product.price * 0.15
    min_p = max(0, int(product.price - price_range))
    max_p = int(product.price + price_range)

    related_products = await crud_product.search_by_vector(
        db, 
        query_vector=product.embedding,
        limit=5,
        min_price=min_p,
        max_price=max_p,
        exclude_id=[product.id]
    )

    reason = (
        f"ê°€ê²©ëŒ€({min_p:,}ì› ~ {max_p:,}ì›)ê°€ ë¹„ìŠ·í•œ ìƒí’ˆ ì¤‘ì—ì„œ, "
        f"'{product.name}'ì™€ ìŠ¤íƒ€ì¼ì´ ê°€ì¥ ìœ ì‚¬í•œ ìƒí’ˆë“¤ì„ ì¶”ì²œí•©ë‹ˆë‹¤."
    )

    return CoordinationResponse(
        answer=reason,
        products=[ProductResponse.model_validate(p) for p in related_products]
    )

@router.get("/related-color/{product_id}", response_model=CoordinationResponse)
async def get_related_by_color(
    product_id: int, 
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user),
) -> CoordinationResponse:
    product = await crud_product.get(db, product_id=product_id)
    if not product or not product.embedding:
        raise HTTPException(status_code=404, detail="ìƒí’ˆì„ ì°¾ê±°ë‚˜ ë²¡í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    color_prompt = (
        f"ìƒí’ˆ '{product.name}'ì˜ ì„¤ëª…('{product.description[:100]}')ì„ ë³´ê³ , "
        f"ê°€ì¥ ì§€ë°°ì ì¸ ìƒ‰ìƒ í‚¤ì›Œë“œ 1ê°œë§Œ (ì˜ˆ: ë¸”ë™, ë„¤ì´ë¹„) ë‹µë³€í•˜ì‹œì˜¤. [100ì ì´ë‚´]"
    )
    
    async with httpx.AsyncClient(timeout=10.0) as client:
        try:
            llm_res = await client.post(
                f"{AI_SERVICE_API_URL}/llm-generate-response", 
                json={"prompt": color_prompt}
            )
            llm_res.raise_for_status()
            target_color = llm_res.json().get("answer", "ìœ ì‚¬ìƒ‰ìƒ")
        except Exception:
            target_color = "ìœ ì‚¬ìƒ‰ìƒ"

    embedding_text = f"{product.name}ê³¼ ë™ì¼í•œ ë””ìì¸, {target_color} ìƒ‰ìƒ"

    color_vector: List[float]
    async with httpx.AsyncClient(timeout=10.0) as client:
        vector_res = await client.post(
            f"{AI_SERVICE_API_URL}/embed-text", 
            json={"text": embedding_text}
        )
        vector_res.raise_for_status()
        color_vector = vector_res.json().get("vector", [])
    
    if not color_vector:
        raise HTTPException(status_code=500, detail="ìƒ‰ìƒ ë²¡í„° ìƒì„± ì‹¤íŒ¨")
        
    related_products = await crud_product.search_by_vector(
        db, 
        query_vector=color_vector,
        limit=5,
        exclude_id=[product.id]
    )
    
    reason = (
        f"'{product.name}'ì˜ ë””ìì¸ì€ ìœ ì§€í•˜ë©´ì„œ, "
        f"'{target_color}' ê³„ì—´ì˜ ë¹„ìŠ·í•œ ìŠ¤íƒ€ì¼ ìƒí’ˆì„ ì¶”ì²œí•©ë‹ˆë‹¤."
    )

    return CoordinationResponse(
        answer=reason,
        products=[ProductResponse.model_validate(p) for p in related_products]
    )

@router.get("/related-brand/{product_id}", response_model=CoordinationResponse)
async def get_related_by_brand(
    product_id: int, 
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user),
) -> CoordinationResponse:
    product = await crud_product.get(db, product_id=product_id)
    if not product or not product.embedding:
        raise HTTPException(status_code=404, detail="ìƒí’ˆì„ ì°¾ê±°ë‚˜ ë²¡í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    style_prompt = (
        f"'{product.name}' ìƒí’ˆì˜ ìŠ¤íƒ€ì¼(ì˜ˆ: ë¯¸ë‹ˆë©€ë¦¬ì¦˜, ìŠ¤íŠ¸ë¦¬íŠ¸) í‚¤ì›Œë“œ 3ê°œë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‹µë³€í•˜ì‹œì˜¤."
    )
    
    async with httpx.AsyncClient(timeout=10.0) as client:
        try:
            llm_res = await client.post(
                f"{AI_SERVICE_API_URL}/llm-generate-response", 
                json={"prompt": style_prompt}
            )
            llm_res.raise_for_status()
            style_keywords = llm_res.json().get("answer", "ìœ ì‚¬ ìŠ¤íƒ€ì¼").split(',')
        except Exception:
            style_keywords = ["ê³ ê¸‰ìŠ¤ëŸ¬ìš´", "ìœ ì‚¬ ë””ìì¸"]

    embedding_text = f"ë‹¤ë¥¸ ë¸Œëœë“œ, {product.category}ì˜ {', '.join(style_keywords)} ìƒí’ˆ"

    brand_vector: List[float]
    async with httpx.AsyncClient(timeout=10.0) as client:
        vector_res = await client.post(
            f"{AI_SERVICE_API_URL}/embed-text", 
            json={"text": embedding_text}
        )
        vector_res.raise_for_status()
        brand_vector = vector_res.json().get("vector", [])
        
    if not brand_vector:
        raise HTTPException(status_code=500, detail="ë¸Œëœë“œ ë²¡í„° ìƒì„± ì‹¤íŒ¨")

    related_products = await crud_product.search_by_vector(
        db, 
        query_vector=brand_vector,
        limit=5,
        exclude_id=[product.id] 
    )

    reason = (
        f"'{product.name}'ì™€ ë¹„ìŠ·í•œ ìŠ¤íƒ€ì¼({', '.join(style_keywords)})ì´ì§€ë§Œ, "
        f"ë‹¤ë¥¸ ë¸Œëœë“œì˜ ìœ ì‚¬ ìƒí’ˆë“¤ì„ ì—„ì„ í•˜ì—¬ ì¶”ì²œí•©ë‹ˆë‹¤."
    )

    return CoordinationResponse(
        answer=reason,
        products=[ProductResponse.model_validate(p) for p in related_products]
    )